{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "3akq3ur2mq6kj7klugqy",
   "authorId": "7914099171838",
   "authorName": "CKOETAS",
   "authorEmail": "chris.koetas@ricoh-usa.com",
   "sessionId": "a6321910-cfa8-47fe-a320-88b53d1fad3a",
   "lastEditTime": 1749150700721
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "Loading_Snowflake_Session"
   },
   "source": "from snowflake.snowpark.context import get_active_session\nsession = get_active_session()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "a245863a-21bf-419c-8342-b3a730e602e4",
   "metadata": {
    "language": "python",
    "name": "cell5",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "!pip install numpy==1.23.5 xgboost pandas==1.5.3 joblib==1.3.2 scikit-learn==1.3.2 tsfresh==0.20.1 category_encoders==2.6.2 scikit-optimize==0.9.0 statsmodels==0.13.5 scipy==1.10.1 tqdm==4.66.1 distributed==2023.3.1 dask==2023.3.1 shap",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "56ab5bec-ca59-4b88-9bf0-2de7f2948de0",
   "metadata": {
    "language": "sql",
    "name": "cell196",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9dab7256-ccc9-4e78-8bee-1332da564b21",
   "metadata": {
    "name": "cell20",
    "collapsed": false
   },
   "source": "# Import all required libraries"
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "Importing_Libraries"
   },
   "source": "import math\nimport pandas as pd\nimport numpy as np\nimport re\nimport os\nimport joblib\nimport sys\nimport sklearn\nimport skopt\nimport shap\nimport category_encoders\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom joblib import dump, load\nfrom datetime import datetime, timedelta\nimport snowflake.snowpark as snowpark\nfrom snowflake.snowpark import Session\nfrom category_encoders.target_encoder import TargetEncoder\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\n\nimport xgboost as xgb\n\nimport tsfresh\nfrom skopt import BayesSearchCV\nfrom skopt.space import Real, Categorical, Integer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nfrom tsfresh.utilities.dataframe_functions import impute\nfrom tsfresh import extract_features, extract_relevant_features, select_features\nfrom tsfresh.utilities.dataframe_functions import impute\nfrom tsfresh.feature_extraction import ComprehensiveFCParameters\nfrom tsfresh.utilities.dataframe_functions import roll_time_series\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "5550ab03-add9-472e-99f2-067ca44402f3",
   "metadata": {
    "language": "python",
    "name": "Library_Version",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "print(\"Python version\",sys.version)\nprint(\"Pandas version\", pd.__version__)\nprint(\"Numpy version\", np.__version__)\nprint(\"Scikit-Learn version\", sklearn.__version__)\nprint(\"Scikit-Optimize version\", skopt.__version__)\nprint(\"XGBoost version\", xgb.__version__)\nprint(\"Category Encoders version\", category_encoders.__version__)\nprint(\"Joblib version\", joblib.__version__)\nprint(\"Ts fresh version\", tsfresh.__version__)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1ea85f10-aa27-49ff-a57a-7619e95e4b64",
   "metadata": {
    "name": "cell47",
    "collapsed": false
   },
   "source": "# UTILITY Function 1"
  },
  {
   "cell_type": "code",
   "id": "b740d828-ff1c-4d27-b09c-5d4bbc219013",
   "metadata": {
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": "def convert_to_float(df):\n    return df.apply(pd.to_numeric, errors='coerce').astype(np.float32)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "737f7bac-090f-4afe-a5e8-b8bcc5fe8437",
   "metadata": {
    "name": "cell48"
   },
   "source": "# UTILITY Function 2"
  },
  {
   "cell_type": "code",
   "id": "a09e5722-1238-4e65-9b6b-064add585da0",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": "def convert_yyyywk_to_date(yyyywk):\n    number_of_days_in_month = {1:31, 2:28, 3:31, 4:30, 5:31, 6:30, 7:31, 8:31, 9:30, 10:31, 11:30, 12:31}\n    time = str(yyyywk)\n    year = int(time[:4])\n    week_no = int(time[4:6])\n   \n    total_days = (week_no*7) - 3\n    days_count = 0\n    cummulative_sum = []\n    cummulative_sum.append(0)\n \n    for key,val in number_of_days_in_month.items():\n        days_count += val\n        if year%4 == 0 and key==2:\n            days_count+=1\n        cummulative_sum.append(days_count)\n \n    first = 0\n    second = 1\n    month = 12\n \n    while second < len(cummulative_sum):\n        if (cummulative_sum[first] <= total_days) and (total_days <= cummulative_sum[second]):\n            month = first+1\n            day = total_days-cummulative_sum[first]\n            break\n        else:\n            first+=1\n            second+=1\n \n    if month<10:\n        month_date = str(year)+\"-0\"+str(month)+\"-01\"\n    else:\n        month_date = str(year)+\"-\"+str(month)+\"-01\"\n    return month_date",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "94f00fef-4163-43b9-addc-dbc48a752e1a",
   "metadata": {
    "language": "python",
    "name": "cell78"
   },
   "outputs": [],
   "source": "def convert_yyyywk_to_actual_mid_date(yyyywk):\n    number_of_days_in_month = {1:31, 2:28, 3:31, 4:30, 5:31, 6:30, 7:31, 8:31, 9:30, 10:31, 11:30, 12:31}\n    time = str(yyyywk)\n    year = int(time[:4])\n    week_no = int(time[4:6])\n    if week_no > 52:\n        week_no = 52\n        \n    total_days = (week_no*7) - 3\n    days_count = 0\n    cummulative_sum = []\n    cummulative_sum.append(0)\n \n    for key,val in number_of_days_in_month.items():\n        days_count += val\n        if year%4 == 0 and key==2:\n            days_count+=1\n        cummulative_sum.append(days_count)\n \n    first = 0\n    second = 1\n    month = 12\n    day = 0\n    while second < len(cummulative_sum):\n        if (cummulative_sum[first] <= total_days) and (total_days <= cummulative_sum[second]):\n            month = first+1\n            day = total_days-cummulative_sum[first]\n            break\n        else:\n            first+=1\n            second+=1\n    \n    day_no=\"00\"\n    \n    if day <10:\n        day_no = \"0\"+str(day)\n    else:\n        day_no = str(day)\n        \n    if month<10:\n        month_date = str(year)+\"-0\"+str(month)+\"-\"+day_no\n    else:\n        month_date = str(year)+\"-\"+str(month)+\"-\"+day_no\n    return month_date",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "55ae5fca-36e6-441e-a30f-7765484b434f",
   "metadata": {
    "language": "python",
    "name": "cell74"
   },
   "outputs": [],
   "source": "def get_days_diff(yyyywk, last_yyyywk):\n    curr = pd.to_datetime(convert_yyyywk_to_actual_mid_date(yyyywk))\n    last = pd.to_datetime(convert_yyyywk_to_actual_mid_date(last_yyyywk))\n    #print(curr, last)\n    days_diff = (last- curr) / np.timedelta64(1, 'D')\n    print(yyyywk, last_yyyywk, days_diff)\n    return days_diff",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "facde1c5-6f12-43a2-b4ef-6a5c2529741a",
   "metadata": {
    "language": "python",
    "name": "cell75"
   },
   "outputs": [],
   "source": "get_days_diff(202318, 202401)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "45b8f9ae-8dc3-42a3-991a-e22b8174a369",
   "metadata": {
    "name": "cell49"
   },
   "source": "# UTILITY Function 3"
  },
  {
   "cell_type": "code",
   "id": "3043d705-2564-4fa8-a38c-d225a70b2b72",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": "def convert_date_to_yyyywk(d):\n        \n    number_of_days_in_month = {1:31, 2:28, 3:31, 4:30, 5:31, 6:30, 7:31, 8:31, 9:30, 10:31, 11:30, 12:31}\n    date = pd.to_datetime(d)\n    month = date.month\n    year = date.year\n    day = date.day\n    week_number = 1\n    days_count = 0\n    cummulative_sum = []\n    cummulative_sum.append(0)\n \n    for key,val in number_of_days_in_month.items():\n        days_count += val\n        if year%4 == 0 and key==2:\n            days_count+=1\n        cummulative_sum.append(days_count)\n    if month<13 and month>0:\n        week_number = math.ceil((cummulative_sum[month-1]+day)/7)\n        \n    yyyywk=\"000000\"\n    if week_number>9:\n        yyyywk = str(year)+str(week_number)\n    else:\n        yyyywk = str(year)+\"0\"+str(week_number)\n    ans = int(yyyywk)    \n    return ans",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "292febd4-ff50-4d6f-aaa1-95c8dc96daa3",
   "metadata": {
    "name": "cell93"
   },
   "source": "# UTILITY Function 4"
  },
  {
   "cell_type": "code",
   "id": "5415b857-32ba-441f-a991-51286349f4a8",
   "metadata": {
    "language": "python",
    "name": "cell92"
   },
   "outputs": [],
   "source": "def engineer_timeseries_cols_using_tsfresh_for_live_customers(only_features):\n    \n    final_features = pd.DataFrame()\n    \n    # Store Dataframe into CSV files for each customer id and dates\n\n    only_features['YYYYWK'] = only_features['YYYYWK'].astype(int)\n    only_features['CUST_ACCOUNT_NUMBER'] = only_features['CUST_ACCOUNT_NUMBER'].astype(int)\n    only_features = only_features.loc[:,~only_features.columns.str.contains('^Unnamed', case=False)]\n    only_features = only_features.fillna(0.0)\n\n    common_cust_id = only_features['CUST_ACCOUNT_NUMBER'].unique()\n    start_time_begin = time.time()\n    \n    count=1\n    for id_ in common_cust_id: \n        print(count)\n        start_time = time.time()\n        flag=False\n        \n        print(id_)    \n\n        only_ts_df = only_features[only_features['CUST_ACCOUNT_NUMBER'] == id_]\n        \n        average_df = only_ts_df.groupby('YYYYWK')[['INVOICE_REVLINE_TOTAL', 'ORIGINAL_AMOUNT_DUE', 'FUNCTIONAL_AMOUNT', 'USED_STORAGE_MB', 'DOCUMENTS_OPENED']].sum()\n        \n        average_df.reset_index(inplace=True)\n        average_df['CUST_ACCOUNT_NUMBER'] = id_\n\n        average_df['YYYYWK'] = average_df['YYYYWK'].astype(int)\n        average_df['CUST_ACCOUNT_NUMBER'] = average_df['CUST_ACCOUNT_NUMBER'].astype(int)\n    \n        #df_test = session.create_dataframe(average_df)\n        #df_test.write.copy_into_location(\"@PS_DOCUWARE_CHURN/only_ts_df\"+str(id_)+\".csv\", file_format_type=\"csv\", format_type_options={\"COMPRESSION\": \"NONE\"}, header=True, overwrite=True )\n        \n        only_ts_df = average_df\n        \n        if only_ts_df.shape[0] > 1:\n            df_rolled = roll_time_series(only_ts_df, column_id=\"CUST_ACCOUNT_NUMBER\", column_sort=\"YYYYWK\")          # roll_time_series\n        elif only_ts_df.shape[0] == 1:\n            flag=True\n            df_rolled = only_ts_df\n            df_rolled['id'] = \"(\"+str(only_ts_df.loc[only_ts_df.index[0],'CUST_ACCOUNT_NUMBER'])+\", \"+str(only_ts_df.loc[only_ts_df.index[0], 'YYYYWK'])+\")\"\n        else:\n            continue\n        \n        columns_to_dropped = set()\n\n        df_rolled_ = df_rolled.loc[:,~df_rolled.columns.str.contains('^(Unnamed|CUST_|YYYYWK|id)', case=False)]\n    \n        df_rolled_imputed = df_rolled_\n        \n        df_rolled_imputed['YYYYWK'] = df_rolled['YYYYWK'].to_list()\n        df_rolled_imputed['ID'] = df_rolled['id'].to_list()\n        df_rolled_imputed['CUST_ACCOUNT_NUMBER'] = df_rolled['CUST_ACCOUNT_NUMBER'].to_list()\n        #df_rolled_imputed.rename(columns={'USED_STORAGE__MB':'USED_STORAGE_MB'}, errors=\"raise\",inplace=True)\n        \n        columns_to_dropped = set()\n\n        df_rolled_imputed = df_rolled_imputed.loc[:,~df_rolled_imputed.columns.str.contains('^Unnamed', case=False)]\n    \n        extraction_settings = ComprehensiveFCParameters()\n\n        if df_rolled_imputed.shape[0] > 0:\n            features = extract_features(df_rolled_imputed, column_id='ID', column_sort='YYYYWK', default_fc_parameters=extraction_settings) #extract_features\n            \n            df_temp = (features.sort_index().iloc[features.shape[0]-1, :]).to_frame().transpose()\n            df_temp['CUST_ACCOUNT_NUMBER'] = id_\n        \n            final_features = pd.concat([final_features, df_temp], axis=0, ignore_index=True)\n            \n        del only_ts_df\n        del features\n        del df_rolled\n        del df_rolled_\n        del df_rolled_imputed\n        \n        end_time = time.time()\n        elapsed_time = end_time - start_time\n        #print(f\"for Cust ID = {id_} Elapsed time: {elapsed_time} seconds\")\n        count+=1\n        #if count == 11:\n        #    break\n    end_time_begin = time.time()\n    elapsed_time_begin = end_time_begin - start_time_begin\n    #print(f\"Total Elapsed time: {elapsed_time_begin} seconds\")\n\n    #Remove unwanted columns\n    final_features_columns = final_features.columns\n    columns_to_be_dropped_from_ts_df = []\n\n    for col in final_features_columns:\n        if re.search(r\"^(Unnamed:|obr_|prtar|CONTRACT_LINE_ITEMS|PROBABILITY_OF_DELINQUENCY|RICOH_CUSTOM_RISK_MODEL|CUST_ACCOUNT_NUMBER_)\", col):\n            columns_to_be_dropped_from_ts_df.append(col)\n\n    final_features_filtered = final_features.drop(columns_to_be_dropped_from_ts_df, axis=1)\n    \n    return final_features_filtered",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "454f0186-8cb6-4d3c-a5d3-5d296950fb34",
   "metadata": {
    "name": "cell50",
    "collapsed": false
   },
   "source": "# UTILITY Function 5"
  },
  {
   "cell_type": "code",
   "id": "ab8c7ee0-40c9-4561-88cd-3fe23a759f6d",
   "metadata": {
    "language": "python",
    "name": "cell7"
   },
   "outputs": [],
   "source": "def engineer_timeseries_cols_using_tsfresh(only_features):\n    \n    final_features = pd.DataFrame()\n    final_calculated = pd.DataFrame()\n    # Store Dataframe into CSV files for each customer id and dates\n\n    only_features['YYYYWK'] = only_features['YYYYWK'].astype(int)\n    only_features['CUST_ACCOUNT_NUMBER'] = only_features['CUST_ACCOUNT_NUMBER'].astype(int)\n    only_features = only_features.loc[:,~only_features.columns.str.contains('^Unnamed', case=False)]\n    only_features = only_features.fillna(0.0)\n\n    common_cust_id = only_features['CUST_ACCOUNT_NUMBER'].unique()\n    start_time_begin = time.time()\n    \n    count=1\n    for id_ in common_cust_id: \n        print(count)\n        start_time = time.time()\n        flag=False\n        \n        print(id_)    \n        calculated = pd.DataFrame(columns=['DAYS_REMAINING'])\n        only_ts_df = only_features[only_features['CUST_ACCOUNT_NUMBER'] == id_]\n        filename = \"@PS_DOCUWARE_CHURN/TSFRESH/all_feature_TSFRESH/only_ts_df_\"+str(id_)+\".csv\"\n        curr_df = session.create_dataframe(only_ts_df)\n        #curr_df.write.copy_into_location(\"@PS_DOCUWARE_CHURN/TSFRESH/all_feature_TSFRESH/only_ts_df\"+str(id_)+\".csv\", file_format_type=\"csv\", format_type_options={\"COMPRESSION\": \"NONE\"}, header=True, overwrite=True )\n        #curr_df.write.csv(filename, overwrite=True, single=True)\n        #session.file.put(only_ts_df, ,overwrite=True)\n        \n       \n        #print( calculated.shape )\n        sum_df = only_ts_df.groupby('YYYYWK')[['INVOICE_REVLINE_TOTAL', 'ORIGINAL_AMOUNT_DUE', 'FUNCTIONAL_AMOUNT', 'USED_STORAGE_MB', 'DOCUMENTS_OPENED']].sum()\n        \n        sum_df.reset_index(inplace=True)\n        sum_df['CUST_ACCOUNT_NUMBER'] = id_\n\n        sum_df['YYYYWK'] = sum_df['YYYYWK'].astype(int)\n        sum_df['CUST_ACCOUNT_NUMBER'] = sum_df['CUST_ACCOUNT_NUMBER'].astype(int)\n    \n        #df_test = session.create_dataframe(sum_df)\n        #df_test.write.copy_into_location(\"@PS_DOCUWARE_CHURN/only_ts_df\"+str(id_)+\".csv\", file_format_type=\"csv\", format_type_options={\"COMPRESSION\": \"NONE\"}, header=True, overwrite=True )\n        \n        only_ts_df = sum_df\n        df_test = session.create_dataframe(sum_df)\n        #df_test.write.copy_into_location(\"@PS_DOCUWARE_CHURN/TSFRESH/all_feature_TSFRESH/sum_ts_df\"+str(id_)+\".csv\", file_format_type=\"csv\", format_type_options={\"COMPRESSION\": \"NONE\"}, header=True, overwrite=True )\n        #print(\"1\", only_ts_df.shape)\n        \n        calculated['DAYS_REMAINING'] = only_ts_df['YYYYWK'].apply(get_days_diff, args=(only_ts_df.loc[only_ts_df.index[only_ts_df.shape[0]-1], 'YYYYWK'],))\n        # print(\"-------------------------------\")\n        # print(calculated['DAYS_REMAINING'].shape)  \n        # print(\"***********\")\n        # print(calculated['DAYS_REMAINING'])\n        # print(\"#####################\")\n        if only_ts_df.shape[0] > 1:\n            df_rolled = roll_time_series(only_ts_df, column_id=\"CUST_ACCOUNT_NUMBER\", column_sort=\"YYYYWK\")          # roll_time_series\n        elif only_ts_df.shape[0] == 1:\n            flag=True\n            df_rolled = only_ts_df\n            df_rolled['id'] = \"(\"+str(only_ts_df.loc[only_ts_df.index[0],'CUST_ACCOUNT_NUMBER'])+\", \"+str(only_ts_df.loc[only_ts_df.index[0], 'YYYYWK'])+\")\"\n        else:\n            continue\n        \n        columns_to_dropped = set()\n\n        df_rolled_ = df_rolled.loc[:,~df_rolled.columns.str.contains('^(Unnamed|CUST_|YYYYWK|id)', case=False)]\n    \n        df_rolled_imputed = df_rolled_\n        \n        df_rolled_imputed['YYYYWK'] = df_rolled['YYYYWK'].to_list()\n        df_rolled_imputed['ID'] = df_rolled['id'].to_list()\n        df_rolled_imputed['CUST_ACCOUNT_NUMBER'] = df_rolled['CUST_ACCOUNT_NUMBER'].to_list()\n        #df_rolled_imputed.rename(columns={'USED_STORAGE__MB':'USED_STORAGE_MB'}, errors=\"raise\",inplace=True)\n        \n        columns_to_dropped = set()\n\n        df_rolled_imputed = df_rolled_imputed.loc[:,~df_rolled_imputed.columns.str.contains('^Unnamed', case=False)]\n    \n        extraction_settings = ComprehensiveFCParameters()\n\n        if df_rolled_imputed.shape[0] > 0:\n            features = extract_features(df_rolled_imputed, column_id='ID', column_sort='YYYYWK', default_fc_parameters=extraction_settings) #extract_features\n            print(\"2\",features.shape)\n            #df_temp = (features.sort_index().iloc[features.shape[0]-1, :]).to_frame().transpose()\n            #df_temp = (features.sort_index().loc[:, :]).transpose()\n            #print(calculated['DAYS_REMAINING'])\n            features['CUST_ACCOUNT_NUMBER'] = id_\n            features = features.reset_index(drop=True)\n            print(\"3\",features.shape)\n            \n            #features_df = session.create_dataframe(features)\n            #features_df.write.copy_into_location(\"@PS_DOCUWARE_CHURN/TSFRESH/all_feature_TSFRESH/features_df\"+str(id_)+\".csv\", file_format_type=\"csv\", format_type_options={\"COMPRESSION\": \"NONE\"}, header=True, overwrite=True )\n        \n        \n            #features_with_age = pd.concat([features, calculated], axis=1, ignore_index=True)\n\n            #features_with_age_df = session.create_dataframe(features_with_age)\n            #features_with_age_df.write.copy_into_location(\"@PS_DOCUWARE_CHURN/TSFRESH/all_feature_TSFRESH/features_with_age_df\"+str(id_)+\".csv\", file_format_type=\"csv\", format_type_options={\"COMPRESSION\": \"NONE\"}, header=True, overwrite=True )\n\n            print(\"4\",features.shape)\n            final_features = pd.concat([final_features, features], axis=0, ignore_index=True)\n            final_calculated = pd.concat([final_calculated, calculated], axis=0, ignore_index=True)\n            #print(calculated['DAYS_REMAINING'])\n            \n            #final_features_df = session.create_dataframe(final_features)\n            #final_features_df.write.copy_into_location(\"@PS_DOCUWARE_CHURN/TSFRESH/all_feature_TSFRESH/final_features_df\"+str(id_)+\".csv\", file_format_type=\"csv\", format_type_options={\"COMPRESSION\": \"NONE\"}, header=True, overwrite=True )\n\n            print(\"5\", final_features.shape)\n            print(\"6\", final_calculated.shape)\n            \n        del only_ts_df\n        del features\n        del df_rolled\n        del df_rolled_\n        del df_rolled_imputed\n        del calculated\n        \n        end_time = time.time()\n        elapsed_time = end_time - start_time\n        #print(f\"for Cust ID = {id_} Elapsed time: {elapsed_time} seconds\")\n        count+=1\n        #if count==5:\n        #    break\n    end_time_begin = time.time()\n    elapsed_time_begin = end_time_begin - start_time_begin\n    #print(f\"Total Elapsed time: {elapsed_time_begin} seconds\")\n\n    #Remove unwanted columns\n    final_features_columns = final_features.columns\n    columns_to_be_dropped_from_ts_df = []\n    #print(final_features.columns)\n    for col in final_features_columns:\n        if re.search(r\"^(Unnamed:|obr_|prtar|CONTRACT_LINE_ITEMS|PROBABILITY_OF_DELINQUENCY|RICOH_CUSTOM_RISK_MODEL|CUST_ACCOUNT_NUMBER_)\", col):\n            columns_to_be_dropped_from_ts_df.append(col)\n\n    final_features_filtered = final_features.drop(columns_to_be_dropped_from_ts_df, axis=1)\n    \n    return final_features_filtered, final_calculated",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "64e8d09b-7012-41b7-b775-c73ac2f2630b",
   "metadata": {
    "language": "python",
    "name": "cell76"
   },
   "outputs": [],
   "source": "#ts_comprehensive_df, ts_age_df = engineer_timeseries_cols_using_tsfresh(final_features_for_FE)\n#ts_comprehensive_df_sf = session.create_dataframe(ts_comprehensive_df)\n#ts_comprehensive_df_sf.write.copy_into_location(\"@PS_DOCUWARE_CHURN/TSFRESH/all_feature_TSFRESH/ts_comprehensive_df.csv\", file_format_type=\"csv\", format_type_options={\"COMPRESSION\": \"NONE\"}, header=True, overwrite=True )\n        \n#session.write_pandas(ts_comprehensive_df, \"PS_DOCUWARE_TSFRESH_FOR_TRAINING\", auto_create_table=True, overwrite = True)\n#session.write_pandas(ts_age_df, \"PS_DOCUWARE_TSFRESH_AGE\", auto_create_table=True, overwrite = True)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6f2b9df5-8591-417e-b4c3-d113d48c7171",
   "metadata": {
    "language": "python",
    "name": "cell79"
   },
   "outputs": [],
   "source": "#ts_comprehensive_df.shape, ts_age_df.shape",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "38c559d1-bd8b-46fe-ad70-2b5487c30755",
   "metadata": {
    "language": "python",
    "name": "cell80"
   },
   "outputs": [],
   "source": "#ts_age_df.head()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b4f4ddec-9111-4934-a7f2-a5a8a89c070c",
   "metadata": {
    "name": "cell51",
    "collapsed": false
   },
   "source": "# UTILITY Function 6"
  },
  {
   "cell_type": "code",
   "id": "21bbc1fa-4cea-4612-b3cb-031c41962aa4",
   "metadata": {
    "language": "python",
    "name": "cell30"
   },
   "outputs": [],
   "source": "def global_shap_importance(model, X):\n    \"\"\" Return a dataframe containing the features sorted by Shap importance\n    Parameters\n    ----------\n    model : The tree-based model \n    X : pd.Dataframe\n         training set/test set/the whole dataset ... (without the label)\n    Returns\n    -------\n    pd.Dataframe\n        A dataframe containing the features sorted by Shap importance\n    \"\"\"\n    explainer = shap.Explainer(model)\n    shap_values = explainer(X)\n    cohorts = {\"\": shap_values}\n    cohort_labels = list(cohorts.keys())\n    cohort_exps = list(cohorts.values())\n    for i in range(len(cohort_exps)):\n        if len(cohort_exps[i].shape) == 2:\n            cohort_exps[i] = cohort_exps[i].abs.mean(0)\n    features = cohort_exps[0].data\n    feature_names = cohort_exps[0].feature_names\n    values = np.array([cohort_exps[i].values for i in range(len(cohort_exps))])\n    feature_importance = pd.DataFrame(\n        list(zip(feature_names, sum(values))), columns=['features', 'importance'])\n    feature_importance.sort_values(\n        by=['importance'], ascending=False, inplace=True)\n    return feature_importance",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8f66bb88-5202-42f7-8c63-4203fa440bda",
   "metadata": {
    "name": "cell132",
    "collapsed": false
   },
   "source": "# UTILITY FUNCTION 7"
  },
  {
   "cell_type": "code",
   "id": "ef12a438-5da7-41db-99dc-d58efb174652",
   "metadata": {
    "language": "python",
    "name": "cell133"
   },
   "outputs": [],
   "source": "def sort_contract_line_items(row):\n    arr = row.split(',')\n    cell_val = \"\"\n    arr_1 = sorted(arr)\n\n    if len(arr_1)>0:\n        cell_val = arr_1[0].strip()\n    for elem in arr_1:\n        cell_val = cell_val+\",\"+elem.strip()\n    return cell_val",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a57288f4-920a-4d69-9038-1a0034e7e2e8",
   "metadata": {
    "name": "cell52",
    "collapsed": false
   },
   "source": "# Raw Data Extraction"
  },
  {
   "cell_type": "code",
   "id": "601c82ba-5271-418e-95c5-c326887f9dfe",
   "metadata": {
    "language": "sql",
    "name": "Sproc_1"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE VIEW RUS_AIML.PS_DOCUWARE_PAYMENTS_V AS SELECT CUSTOMER_NO, RECEIPT_DATE, FUNCTIONAL_AMOUNT FROM RUS_AIML.PS_DOCUWARE_PAYMENTS;\n\nCREATE OR REPLACE VIEW RUS_AIML.PS_DOCUWARE_REVENUE_V AS SELECT CUST_ACCOUNT_NUMBER, DATE_INVOICE_GL_DATE, INVOICE_REVLINE_TOTAL FROM RUS_AIML.PS_DOCUWARE_REVENUE;\n\nCREATE OR REPLACE VIEW RUS_AIML.PS_DOCUWARE_TRX_V AS SELECT ACCOUNT_NUMBER, TRX_DATE, ORIGINAL_AMOUNT_DUE FROM RUS_AIML.PS_DOCUWARE_TRX;\n\nCREATE OR REPLACE VIEW RUS_AIML.PS_DOCUWARE_CONTRACTS_SUBLINE_V AS SELECT CUST_ACCOUNT_NUMBER, SLINE_START_DATE, SLINE_END_DATE, SLINE_STATUS FROM RUS_AIML.PS_DOCUWARE_CONTRACT_SUBLINE;\n\nCREATE OR REPLACE VIEW RUS_AIML.PS_DOCUWARE_RENEWALS_V AS SELECT TO_CHAR(BILLTOCUSTOMERNUMBER) AS BILLTOCUSTOMERNUMBER, TO_CHAR(SHIPTOCUSTNUM) AS SHIPTOCUSTNUM, STARTDATECOVERAGE, CONTRACT_END_DATE FROM RUS_AIML.PS_DOCUWARE_SSCD_RENEWALS;\n\nCREATE OR REPLACE VIEW RUS_AIML.PS_DOCUWARE_L1_CUST_V AS SELECT CUST_ACCOUNT_NUMBER, CUST_PARTY_NAME, L3_RISE_CONSOLIDATED_NUMBER, L3_RISE_CONSOLIDATED_NAME, L2_RISE_CONSOLIDATED_NUMBER, L2_RISE_CONSOLIDATED_NAME, CUST_ACCOUNT_TYPE, CUSTOMER_SEGMENT, CUSTOMER_SEGMENT_LEVEL, CHURNED_FLAG, CHURN_DATE FROM RUS_AIML.PS_DOCUWARE_L1_CUST;\n\nCREATE OR REPLACE VIEW RUS_AIML.DNB_RISK_BREAKDOWN_V AS SELECT TO_CHAR(ACCOUNT_NUMBER) AS ACCOUNT_NUMBER, OVERALL_BUSINESS_RISK, RICOH_CUSTOM_RISK_MODEL, PROBABILITY_OF_DELINQUENCY, PAYMENT_RISK_TRIPLE_A_RATING FROM RUS_AIML.DNB_RISK_BREAKDOWN;\n\nCREATE OR REPLACE VIEW RUS_AIML.DOCUWARE_USAGE_JAPAN_V1_LATEST_V AS\n--select * from RUS_AIML.DOCUWARE_USAGE_JAPAN_V1_LATEST_V_IMPUTED; -- where YYYYWK > 202152;\n WITH latback AS (\n   SELECT DISTINCT CONTRACT_NUMBER\n    ,REGEXP_REPLACE(trim(CUSTOMER_NAME), '  ', ' ') AS CUSTOMER_NAME,\n    CONTRACT_START\n    ,CONTRACT_END\n    ,DOCUMENTS_OPENED\n    ,USED_STORAGE__MB\n    ,CONTRACT_LINE_ITEMS\n    ,PERIOD\n    ,YYYYWK\n   FROM DOCUWARE_USAGE_JAPAN_20250513_SNAP\n   WHERE RICOH_REGIONS = 'US/Canada'\n    AND ADP__CURRENT != 'Ricoh Canada Inc.'\n   )\n  ,jaro AS (\n   SELECT DISTINCT a.CUST_ACCOUNT_NUMBER,\n   a.churn_date,\n   a.churned_flag\n    ,b.CONTRACT_NUMBER\n    ,a.CUST_PARTY_NAME\n    ,b.CUSTOMER_NAME,\n    b.CONTRACT_START\n    ,b.CONTRACT_END\n    ,b.DOCUMENTS_OPENED\n    ,b.USED_STORAGE__MB\n    ,b.CONTRACT_LINE_ITEMS\n    ,b.PERIOD\n    ,b.YYYYWK\n    ,jarowinkler_similarity(a.CUST_PARTY_NAME, b.CUSTOMER_NAME)\n    ,rank() OVER (\n     PARTITION BY a.CUST_ACCOUNT_NUMBER ORDER BY jarowinkler_similarity(a.CUST_PARTY_NAME, b.CUSTOMER_NAME) DESC\n     ) AS match_rank\n   FROM RUS_AIML.PS_DOCUWARE_L1_CUST a\n   FULL OUTER JOIN latback b\n   WHERE jarowinkler_similarity(a.CUST_PARTY_NAME, b.CUSTOMER_NAME) BETWEEN 93\n     AND 100\n   )\nSELECT *\nFROM jaro\nWHERE jaro.match_rank = 1\n AND EXISTS (\n  SELECT 1\n  FROM jaro\n  );\n ",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0016c620-4879-4a00-9d5a-b0648e864243",
   "metadata": {
    "name": "cell11",
    "collapsed": false
   },
   "source": ""
  },
  {
   "cell_type": "code",
   "id": "fc13c2da-a095-493e-b060-bbe9c5cb7a4d",
   "metadata": {
    "language": "python",
    "name": "Impute_Missing_Usage_23"
   },
   "outputs": [],
   "source": "#Code to impute missing usage data for first half of 2023\nusage_latest = session.sql(\"SELECT * FROM RUS_AIML.DOCUWARE_USAGE_JAPAN_V1_LATEST_V\").to_pandas()\n\nusage_latest['CONTRACT_START'] = pd.to_datetime(usage_latest['CONTRACT_START'])\nusage_latest['CHURN_DATE']= pd.to_datetime(usage_latest['CHURN_DATE'])\n\n#Focus only on Contract Start Date >= ‘2020-01-01’\nusageFIX = usage_latest[usage_latest['CONTRACT_START']>= '2020-01-01' ]\n\n# Active -  If contract start date <= 2022-12-31  for active then we need to add weekly usage numbers ( average of last 10 for numerical)\nusageFIXActive = usageFIX[(usageFIX['CONTRACT_START']<= '2022-12-31') & (usageFIX['CHURNED_FLAG']== False) & (usageFIX['YYYYWK'] <= 202252) ]\n\nidx = usageFIXActive.groupby('CUST_ACCOUNT_NUMBER')['YYYYWK'].idxmax()\nmax_scores = usageFIXActive.loc[idx]\ndf_duplicated = pd.DataFrame(np.repeat(max_scores.values, repeats=25, axis=0), columns=max_scores.columns)\ndf_duplicated= df_duplicated.sort_values(by = 'CUST_ACCOUNT_NUMBER')\n\n#range of YYYYWK missing data\nrecurring_range = []\n\nfor i in range(1,26):\n\n    if i < 10:\n        month_date = str(2023)+\"0\"+str(i)\n    else:\n        month_date = str(2023)+str(i)\n    recurring_range.append(month_date)\n\n# Calculate how many times the range needs to repeat\nnum_repeats = len(max_scores)    #len(df) // len(recurring_range) + 1\n\n# Create the new column values by repeating the range and truncating\nnew_column = np.tile(recurring_range, num_repeats)[:len(df_duplicated)]\n\n# Replace the column\ndf_duplicated['YYYYWK'] = new_column\n\n# Active account imputations\nActiveAccts = df_duplicated\n\n#End Active customer imputation\n\n#Churned Customer imputation\n\n# Churned Customers part 1    If contract start date <= 2022-12-31  and churned date after > 2022-12-31 then add in usage for wks between 202301-202325\nusageFIXChurned1 = usageFIX[(usageFIX['CONTRACT_START']<= '2022-12-31') & (usageFIX['CHURNED_FLAG']== True) &  (usageFIX['CHURN_DATE'] > '2023-06-24' ) & (usageFIX['YYYYWK'] <= 202252)   ]\n\nidx = usageFIXChurned1.groupby('CUST_ACCOUNT_NUMBER')['YYYYWK'].idxmax()\nmax_scores = usageFIXChurned1.loc[idx]\ndf_duplicated = pd.DataFrame(np.repeat(max_scores.values, repeats=25, axis=0), columns=max_scores.columns)\ndf_duplicated.sort_values(by = 'CUST_ACCOUNT_NUMBER')\n\n# Calculate how many times the range needs to repeat\nnum_repeats = len(max_scores)   #len(df) // len(recurring_range) + 1\n\n# Create the new column values by repeating the range and truncating\nnew_column = np.tile(recurring_range, num_repeats)[:len(df_duplicated)]\n\n# Replace the column\ndf_duplicated['YYYYWK'] = new_column\n\n# save imputations for part 1 of churned customers\nchurned1 = df_duplicated\n\n# end churned customer part1 \n\n# Churned Customers part 2 those customers who churned during the data outage\nusageFIXChurned2 = usageFIX[(usageFIX['CONTRACT_START']<= '2022-12-31') & (usageFIX['CHURNED_FLAG']== True) &  (usageFIX['CHURN_DATE'] <= '2023-06-24' ) & (usageFIX['YYYYWK'] <= 202252) & (usageFIX['CHURN_DATE'] >= '2023-01-01' )  ]\n\nidx = usageFIXChurned2.groupby('CUST_ACCOUNT_NUMBER')['YYYYWK'].idxmax()\nmax_scores = usageFIXChurned2.loc[idx]\nmax_scores['ywk'] = [(i -pd.to_datetime('2023-01-01')).days//7 for i in max_scores['CHURN_DATE']]\n\n# Method to duplicate rows\ndf_duplicated = max_scores.loc[np.repeat(max_scores.index.values, max_scores['ywk'])]\n\n# Reset index if needed\ndf_duplicated = df_duplicated.reset_index(drop=True)\n\n# Replace hard coded range\nstart_index = 0\nend_index = 23\nnew_values = recurring_range[0:24]\n\ndf_duplicated.loc[start_index:end_index, 'YYYYWK'] = new_values\n\n#  Replace hard coded range\nstart_index = 24\nend_index = 46\nnew_values = recurring_range[0:23]\n\ndf_duplicated.loc[start_index:end_index, 'YYYYWK'] = new_values\n\n#  Replace hard coded range\nstart_index = 47\nend_index = 56\nnew_values = recurring_range[0:10]\n\ndf_duplicated.loc[start_index:end_index, 'YYYYWK'] = new_values\n\n# Replace hard coded range\nstart_index = 57\nend_index = 80\nnew_values = recurring_range[0:24]\n\ndf_duplicated.loc[start_index:end_index, 'YYYYWK'] = new_values\n\n# Replace hard coded range\nstart_index = 81\nend_index = 87\nnew_values = recurring_range[0:7]\n\ndf_duplicated.loc[start_index:end_index, 'YYYYWK'] = new_values\n\n\n# save imputations for part 2 of churned customers\nchurned2 = df_duplicated\n\n\n#Combine imputations\nimputations = pd.concat([ActiveAccts,churned1,churned2])\n# drop added columns from imputations\nimputations = imputations.drop(columns=['Unnamed: 0','ywk'])\n\nusage = pd.concat([usageFIX,imputations])\n\n\n\n\nusage_latest = usage",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "af20d92d-a924-4f19-abc4-c0984d7ccdfc",
   "metadata": {
    "language": "python",
    "name": "cell208"
   },
   "outputs": [],
   "source": "",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c92c205e-756d-4f21-8768-aae6519ca187",
   "metadata": {
    "language": "python",
    "name": "cell71"
   },
   "outputs": [],
   "source": "#merge_final",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a65221c4-09cc-4269-8116-3255f7d99aec",
   "metadata": {
    "language": "python",
    "name": "cell16"
   },
   "outputs": [],
   "source": "#l1_cust_df.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "968c5c15-e939-48f1-af90-06fd29051e82",
   "metadata": {
    "language": "sql",
    "name": "cell14"
   },
   "outputs": [],
   "source": "-- SELECT * FROM RUS_AIML.PS_DOCUWARE_L1_CUST limit 2;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c80c3824-51e1-4224-aefc-e12b899d1c6c",
   "metadata": {
    "language": "python",
    "name": "cell9"
   },
   "outputs": [],
   "source": "# #Fetching from previous SPROC output table\n# raw_df = session.sql(\"SELECT * FROM RAC_RAPID_DEV.RUS_AIML.PS_DOCUWARE_RAW_DATA_EXTRACTION\").to_pandas()\n\n# non_ts_numeric_cols = [\"PROBABILITY_OF_DELINQUENCY\", \"RICOH_CUSTOM_RISK_MODEL\"]\n# non_ts_categorical_cols = [\"OVERALL_BUSINESS_RISK\", \"PAYMENT_RISK_TRIPLE_A_RATING\", \"CONTRACT_LINE_ITEMS\"]\n# columns_to_be_processed_later = non_ts_numeric_cols + non_ts_categorical_cols + [\"CUST_ACCOUNT_NUMBER\", \"LIFESPAN_MONTHS\"]\n# finalized_df_ohe_to_process = raw_df.groupby(\"CUST_ACCOUNT_NUMBER\")[columns_to_be_processed_later].first()\n\n# # Imputation for Non Time Series columns\n# pofd_median = finalized_df_ohe_to_process[\"PROBABILITY_OF_DELINQUENCY\"].median()\n# finalized_df_ohe_to_process[\"PROBABILITY_OF_DELINQUENCY\"] = finalized_df_ohe_to_process[\"PROBABILITY_OF_DELINQUENCY\"].apply(lambda x:   float(pofd_median) if np.isnan(x) else x)\n\n# temp=finalized_df_ohe_to_process[\"RICOH_CUSTOM_RISK_MODEL\"].mode().to_frame()\n# rcrm_mode = temp.loc[temp.index[0], 'RICOH_CUSTOM_RISK_MODEL']\n# finalized_df_ohe_to_process[\"RICOH_CUSTOM_RISK_MODEL\"] = finalized_df_ohe_to_process[\"RICOH_CUSTOM_RISK_MODEL\"].apply(lambda x: float(rcrm_mode) if np.isnan(x) else x)\n\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2f456a72-24e8-4e57-b6b8-5ee256cf93e7",
   "metadata": {
    "name": "cell134"
   },
   "source": "# Preprocessing Raw Data"
  },
  {
   "cell_type": "code",
   "id": "791bf39c-10fd-4c91-8ee9-6d3f2d9c41f3",
   "metadata": {
    "language": "python",
    "name": "Sproc_2"
   },
   "outputs": [],
   "source": "#Fetching all the different views\npay_df = session.sql(\"SELECT * FROM RUS_AIML.PS_DOCUWARE_PAYMENTS_V\").to_pandas()\nrev_df = session.sql(\"SELECT * FROM RUS_AIML.PS_DOCUWARE_REVENUE_V\").to_pandas()\ntrx_df = session.sql(\"SELECT * FROM RUS_AIML.PS_DOCUWARE_TRX_V\").to_pandas()\ncontracts_sub_df = session.sql(\"SELECT * FROM RUS_AIML.PS_DOCUWARE_CONTRACTS_SUBLINE_V\").to_pandas()\nrenewals_df = session.sql(\"SELECT * FROM RUS_AIML.PS_DOCUWARE_RENEWALS_V\").to_pandas()\nl1_cust_df =  session.sql(\"SELECT * FROM RUS_AIML.PS_DOCUWARE_L1_CUST_V\").to_pandas()\ndnb_risk_df = session.sql(\"SELECT * FROM RUS_AIML.DNB_RISK_BREAKDOWN_V\").to_pandas()\n#usage_latest = session.sql(\"SELECT * FROM RUS_AIML.DOCUWARE_USAGE_JAPAN_V1_LATEST_V\").to_pandas()\n\n# Removing duplicates from all the pandas dataframes\npay_df = pay_df.drop_duplicates()\nrev_df = rev_df.drop_duplicates()\ntrx_df = trx_df.drop_duplicates()\ncontracts_sub_df = contracts_sub_df.drop_duplicates()\nrenewals_df = renewals_df.drop_duplicates()\nl1_cust_df = l1_cust_df.drop_duplicates()\ndnb_risk_df = dnb_risk_df.drop_duplicates()\nusage_latest = usage_latest.drop_duplicates()\n\n# Selecting only churned customers\n\nl1_cust_churned = l1_cust_df[l1_cust_df[\"CHURNED_FLAG\"]==True]\n\npay_df_churned = pay_df.merge(l1_cust_churned[[\"CUST_ACCOUNT_NUMBER\"]], left_on = \"CUSTOMER_NO\", right_on = \"CUST_ACCOUNT_NUMBER\", how=\"inner\")\npay_df_churned = pay_df_churned.drop(\"CUSTOMER_NO\", axis=1)\npay_df_churned[\"RECEIPT_DATE\"] = pd.to_datetime(pay_df_churned[\"RECEIPT_DATE\"])\npay_df_churned = pay_df_churned.groupby([\"CUST_ACCOUNT_NUMBER\", \"RECEIPT_DATE\"]).agg('sum').reset_index()\npay_df_churned[\"MONTH\"] = pd.to_datetime(pay_df_churned[\"RECEIPT_DATE\"])\n\nrev_df_churned = rev_df.merge(l1_cust_churned[[\"CUST_ACCOUNT_NUMBER\"]], on = \"CUST_ACCOUNT_NUMBER\", how=\"inner\")\nrev_df_churned[\"DATE_INVOICE_GL_DATE\"] = pd.to_datetime(rev_df_churned[\"DATE_INVOICE_GL_DATE\"])\nrev_df_churned = rev_df_churned.groupby([\"CUST_ACCOUNT_NUMBER\", \"DATE_INVOICE_GL_DATE\"]).agg('sum').reset_index()\nrev_df_churned[\"MONTH\"] = pd.to_datetime(rev_df_churned[\"DATE_INVOICE_GL_DATE\"])\n\ntrx_df_churned = trx_df.merge(l1_cust_churned[[\"CUST_ACCOUNT_NUMBER\"]], left_on = \"ACCOUNT_NUMBER\", right_on = \"CUST_ACCOUNT_NUMBER\", how=\"inner\")\ntrx_df_churned = trx_df_churned.drop(\"ACCOUNT_NUMBER\", axis=1)\ntrx_df_churned[\"TRX_DATE\"] = pd.to_datetime(trx_df_churned[\"TRX_DATE\"])\ntrx_df_churned = trx_df_churned.groupby([\"CUST_ACCOUNT_NUMBER\", \"TRX_DATE\"]).agg('sum').reset_index()\ntrx_df_churned[\"MONTH\"] = pd.to_datetime(trx_df_churned[\"TRX_DATE\"])\n\np_r_t_merged = pay_df_churned.merge(rev_df_churned, on = [\"CUST_ACCOUNT_NUMBER\",\"MONTH\"], how=\"outer\").merge(trx_df_churned, on = [\"CUST_ACCOUNT_NUMBER\",\"MONTH\"], how=\"outer\")\n\n#Contracts Subline\ncontracts_sub_df[\"SLINE_START_DATE\"] = pd.to_datetime(contracts_sub_df[\"SLINE_START_DATE\"])\ncontracts_sub_df[\"SLINE_END_DATE\"] = pd.to_datetime(contracts_sub_df[\"SLINE_END_DATE\"])\n\ncontracts_sub_df[\"SUB_EARLIEST_DATE\"] = contracts_sub_df.groupby(\"CUST_ACCOUNT_NUMBER\")[\"SLINE_START_DATE\"].transform(\"min\")\ncontracts_sub_df[\"SUB_LATEST_DATE\"] = contracts_sub_df.groupby(\"CUST_ACCOUNT_NUMBER\")[\"SLINE_END_DATE\"].transform(\"max\")\ncontracts_sub_df_churned = contracts_sub_df.merge(l1_cust_churned[[\"CUST_ACCOUNT_NUMBER\"]], on = \"CUST_ACCOUNT_NUMBER\", how=\"inner\")\n\ncontracts_sub_df_churned = contracts_sub_df_churned.drop_duplicates()\n\n# Renewals\ncols_to_str = [\"BILLTOCUSTOMERNUMBER\",\"SHIPTOCUSTNUM\"]\nrenewals_df[cols_to_str] = renewals_df[cols_to_str].astype(\"Int64\").astype(str)\n\nrenewals_df_churned_1 = renewals_df.merge(l1_cust_churned[[\"CUST_ACCOUNT_NUMBER\"]], left_on = \"SHIPTOCUSTNUM\", right_on = \"CUST_ACCOUNT_NUMBER\",  how=\"left\")\n\nrenewals_df_churned_2 = renewals_df_churned_1.merge(l1_cust_churned[[\"CUST_ACCOUNT_NUMBER\"]], left_on = \"BILLTOCUSTOMERNUMBER\", right_on = \"CUST_ACCOUNT_NUMBER\",  how=\"left\", suffixes = (\"_1\", \"_2\"))\nrenewals_df_churned_2[\"CUST_ACCOUNT_NUMBER\"] = renewals_df_churned_2[\"CUST_ACCOUNT_NUMBER_1\"].fillna(renewals_df_churned_2[\"CUST_ACCOUNT_NUMBER_2\"])\nrenewals_df_churned_2 = renewals_df_churned_2.drop([\"BILLTOCUSTOMERNUMBER\", \"SHIPTOCUSTNUM\",\"CUST_ACCOUNT_NUMBER_1\",\"CUST_ACCOUNT_NUMBER_2\"], axis=1)\nrenewals_df_churned_2 = renewals_df_churned_2.dropna()\n\nrenewals_df_churned_2[\"STARTDATECOVERAGE\"] =  pd.to_datetime(renewals_df_churned_2[\"STARTDATECOVERAGE\"])\nrenewals_df_churned_2[\"RENEWALS_EARLIEST_DATE\"] = renewals_df_churned_2.groupby(renewals_df_churned_2[\"CUST_ACCOUNT_NUMBER\"])[\"STARTDATECOVERAGE\"].transform(\"min\")\nrenewals_df_churned_2[\"RENEWALS_LATEST_DATE\"] = renewals_df_churned_2.groupby(renewals_df_churned_2[\"CUST_ACCOUNT_NUMBER\"])[\"CONTRACT_END_DATE\"].transform(\"max\")\n\n#DNB Risk Breakdown\ndnb_risk_df[\"ACCOUNT_NUMBER\"] = dnb_risk_df[\"ACCOUNT_NUMBER\"].astype(\"Int64\").astype(str)\ndnb_risk_df_churned = dnb_risk_df.merge(l1_cust_churned[[\"CUST_ACCOUNT_NUMBER\"]], left_on = \"ACCOUNT_NUMBER\", right_on = \"CUST_ACCOUNT_NUMBER\",  how=\"inner\")\ndnb_risk_df_churned = dnb_risk_df_churned.drop(\"ACCOUNT_NUMBER\", axis=1)\n\nusage_latest[\"YYYYWK_Transformed\"] = pd.to_datetime(usage_latest[\"YYYYWK\"].apply(convert_yyyywk_to_actual_mid_date), errors = \"coerce\")\n\n#Usage Japan Latest\nusage_latest[\"CUST_ACCOUNT_NUMBER\"] = usage_latest[\"CUST_ACCOUNT_NUMBER\"].astype(\"Int64\").astype(str)\nusage_latest[\"YYYYWK_MONTH\"] = pd.to_datetime(usage_latest[\"YYYYWK_Transformed\"])\n\n# Adding Aggregate syntax using Group by on YYYYWK_MONTH\nusage_latest['CONTRACT_LINE_ITEMS_CANONICAL_FORM'] = usage_latest['CONTRACT_LINE_ITEMS'].apply(sort_contract_line_items)\nusage_latest.drop(['PERIOD', 'CONTRACT_LINE_ITEMS'], inplace=True, axis=1)\nusage_latest = usage_latest.drop_duplicates()\ndf_full_final = usage_latest.dropna(subset=['CONTRACT_LINE_ITEMS_CANONICAL_FORM']).assign(something=lambda x:x['CONTRACT_LINE_ITEMS_CANONICAL_FORM'].str.len()).sort_values(['CUST_ACCOUNT_NUMBER','YYYYWK','something'], ascending=[True, True, False]).groupby(['CUST_ACCOUNT_NUMBER', 'YYYYWK'], as_index=False).head(1)\nusage_latest = df_full_final.drop('something', axis=1)\nusage_latest = usage_latest.rename(columns={'CONTRACT_LINE_ITEMS_CANONICAL_FORM':'CONTRACT_LINE_ITEMS'})",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "61ea227f-1ff3-4d3a-ac51-013a85d002ac",
   "metadata": {
    "language": "python",
    "name": "cell137"
   },
   "outputs": [],
   "source": "",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f83f6f11-25f6-4dec-ade1-c4b5d32ff391",
   "metadata": {
    "language": "python",
    "name": "cell136"
   },
   "outputs": [],
   "source": "usage_latest.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "55e72d11-fa47-4a6f-a93b-713467e76298",
   "metadata": {
    "language": "python",
    "name": "cell138"
   },
   "outputs": [],
   "source": "usage_latest_churned = usage_latest.merge(l1_cust_churned[[\"CUST_ACCOUNT_NUMBER\"]], on=\"CUST_ACCOUNT_NUMBER\",  how=\"inner\")\n\n# Merging all the churned customers data frames i.e. Payments, Revenue, Transactions, contracts, contracts subline, contracts topline, renewals, snow inc, tech survey, loyalty survey, dnb risk and usage latest\n\nmerged_1 = p_r_t_merged.merge(contracts_sub_df_churned, left_on = [\"CUST_ACCOUNT_NUMBER\", \"MONTH\"], right_on = [\"CUST_ACCOUNT_NUMBER\", \"SLINE_START_DATE\"], how=\"outer\")\nmerged_1[\"MONTH\"] = merged_1[\"MONTH\"].fillna(merged_1[\"SLINE_START_DATE\"])\n\nmerged_2 = merged_1.merge(renewals_df_churned_2, left_on = [\"CUST_ACCOUNT_NUMBER\",\"MONTH\"], right_on = [\"CUST_ACCOUNT_NUMBER\",\"STARTDATECOVERAGE\"], how=\"outer\")\nmerged_2[\"MONTH\"] = merged_2[\"MONTH\"].fillna(merged_2[\"STARTDATECOVERAGE\"])",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fa9e3f0d-240d-4124-8a12-58e94a0723a9",
   "metadata": {
    "language": "python",
    "name": "cell140"
   },
   "outputs": [],
   "source": "usage_latest_churned[\"YYYYWK_MONTH\"].unique()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3b8e4ec8-345c-46cd-8edb-c5b4423a826f",
   "metadata": {
    "language": "python",
    "name": "cell139"
   },
   "outputs": [],
   "source": "merged_2[\"STARTDATECOVERAGE\"].unique()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "db6bdb0f-6b15-43f8-a776-74c2f60e3b5d",
   "metadata": {
    "language": "python",
    "name": "cell135"
   },
   "outputs": [],
   "source": "\n\nmerged_3 = merged_2.merge(dnb_risk_df_churned, on=\"CUST_ACCOUNT_NUMBER\", how=\"left\")\n\nmerged_4 = merged_3.merge(usage_latest_churned, left_on= [\"CUST_ACCOUNT_NUMBER\",\"MONTH\"], right_on = [\"CUST_ACCOUNT_NUMBER\", \"YYYYWK_MONTH\"], how=\"outer\")\nmerged_4[\"MONTH\"] = merged_4[\"MONTH\"].fillna(merged_4[\"YYYYWK_MONTH\"])\n\nto_drop_2 = [\"CONTRACT_NUMBER\", \"CUST_PARTY_NAME\", \"CUSTOMER_NAME\", \"CONTRACT_END\",\"JAROWINKLER_SIMILARITY\"]\n#(A.CUST_PARTY_NAME, B.CUSTOMER_NAME) removed from jaro winkler\n\nmerged_5 = merged_4.drop(to_drop_2, axis=1)\n\n#merged_5 = merged_4.merge(l1_cust_churned[[\"CUST_ACCOUNT_NUMBER\", \"CHURNED_FLAG\", \"CHURN_DATE\"]], on = \"CUST_ACCOUNT_NUMBER\", how=\"inner\")\n\nmerged_5[\"EARLIEST_DATE\"] = merged_5[[\"RECEIPT_DATE\", \"DATE_INVOICE_GL_DATE\", \"TRX_DATE\", \"SLINE_START_DATE\", \"STARTDATECOVERAGE\"]].min(axis=1)\nmerged_5[\"FINAL_EARLIEST_DATE\"] = merged_5.groupby(\"CUST_ACCOUNT_NUMBER\")[\"EARLIEST_DATE\"].transform(\"min\")\n\nmerged_5[\"CHURN_DATE\"] = pd.to_datetime(merged_5[\"CHURN_DATE\"])\nmerged_5[\"CHURN_MONTH\"] = pd.to_datetime(merged_5[\"CHURN_DATE\"]).dt.to_period(\"M\").dt.to_timestamp()\n\n\nmerged_5[\"LIFESPAN_MONTHS\"] = ((merged_5[\"CHURN_DATE\"] - merged_5[\"FINAL_EARLIEST_DATE\"]).dt.days) / 30\nmerged_5[\"DAYS_TO_CHURN\"]  = ((merged_5[\"CHURN_DATE\"] - merged_5[\"FINAL_EARLIEST_DATE\"]).dt.days)\n\nto_drop_3 = [\"SLINE_END_DATE\", \"SLINE_STATUS\", \"SUB_EARLIEST_DATE\", \"SUB_LATEST_DATE\", \"RENEWALS_EARLIEST_DATE\", \"RENEWALS_LATEST_DATE\", \"CONTRACT_END_DATE\", \"CHURNED_FLAG\",\"CHURN_MONTH\", \"EARLIEST_DATE\"]\n\nmerged_5 = merged_5.drop(to_drop_3, axis=1)\n\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "db362f63-54e4-42c2-8578-960a2c441f55",
   "metadata": {
    "language": "python",
    "name": "cell180"
   },
   "outputs": [],
   "source": "merged_5.columns",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6337ad28-4401-48a6-b0c0-50b8228d0a5c",
   "metadata": {
    "language": "python",
    "name": "cell142"
   },
   "outputs": [],
   "source": "merged_5[\"STARTDATECOVERAGE\"].unique()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8e23d0ca-bd10-403e-8129-a06e6029b87c",
   "metadata": {
    "language": "python",
    "name": "cell143"
   },
   "outputs": [],
   "source": "merged_5[\"YYYYWK_MONTH\"].unique()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "935527d7-0733-45d4-94dc-62d96463c26d",
   "metadata": {
    "language": "python",
    "name": "cell144"
   },
   "outputs": [],
   "source": "merged_5[\"DATE_INVOICE_GL_DATE\"].unique()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1407b93d-701f-495f-b52c-79c987dcf735",
   "metadata": {
    "language": "python",
    "name": "cell147"
   },
   "outputs": [],
   "source": "date_col = [\"MONTH\",\"YYYYWK_Transformed\", \"FINAL_EARLIEST_DATE\", \"CHURN_DATE\"]\n\nmerged_5[date_col] = merged_5[date_col].astype(str)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c9f51157-5251-4c9f-8a83-8b3a075b8c33",
   "metadata": {
    "language": "python",
    "name": "cell145"
   },
   "outputs": [],
   "source": "\nmerged_5 = merged_5.drop_duplicates()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bcd595c9-3b11-4907-9859-e54a6a30eb5e",
   "metadata": {
    "language": "python",
    "name": "cell146"
   },
   "outputs": [],
   "source": "merged_5.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a30f2f1c-526e-4bf5-b472-a6233754f7e2",
   "metadata": {
    "language": "python",
    "name": "cell148"
   },
   "outputs": [],
   "source": "#usage_latest_churned['CUST_ACCOUNT_NUMBER'].unique()\n\ntemp = pd.DataFrame({'CUST_ACCOUNT_NUMBER':usage_latest_churned['CUST_ACCOUNT_NUMBER'].unique()})\nmerge_final = merged_5.merge(temp, on='CUST_ACCOUNT_NUMBER', how='inner')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "da7103eb-879d-4255-bf87-c68303191458",
   "metadata": {
    "language": "python",
    "name": "cell149"
   },
   "outputs": [],
   "source": "merge_final[\"DATE_INVOICE_GL_DATE\"].unique()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c840820b-706c-4023-8c1c-237c75d1df81",
   "metadata": {
    "language": "python",
    "name": "cell150"
   },
   "outputs": [],
   "source": "merge_final[\"STARTDATECOVERAGE\"].unique()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "54b27072-d685-43f8-8c9c-e25f3b7c51ba",
   "metadata": {
    "language": "python",
    "name": "cell151"
   },
   "outputs": [],
   "source": "merge_final[\"YYYYWK_MONTH\"].unique()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f2ac6afe-896b-47a2-bd79-873338940a5e",
   "metadata": {
    "language": "python",
    "name": "cell152"
   },
   "outputs": [],
   "source": "merge_final[\"RECEIPT_DATE\"].unique()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a4153764-7cb7-4707-8fad-5da34b596280",
   "metadata": {
    "language": "python",
    "name": "cell153"
   },
   "outputs": [],
   "source": "merge_final[\"RECEIPT_DATE\"]= pd.to_datetime(merge_final[\"RECEIPT_DATE\"])\nmerge_final[\"YYYYWK_MONTH\"]= pd.to_datetime(merge_final[\"YYYYWK_MONTH\"])\nmerge_final[\"DATE_INVOICE_GL_DATE\"] = pd.to_datetime(merge_final[\"DATE_INVOICE_GL_DATE\"])\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "93ba2c4f-853a-4a1d-9f18-9effba09e2c6",
   "metadata": {
    "language": "python",
    "name": "cell77"
   },
   "outputs": [],
   "source": "merge_final[\"DATE_INVOICE_GL_DATE\"].head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0fe340db-f336-4557-a101-6ec833e0fc50",
   "metadata": {
    "language": "python",
    "name": "cell160"
   },
   "outputs": [],
   "source": "def timestamp_To_Date(row):\n    if type(row) == pd._libs.tslibs.nattype.NaTType:\n        return None\n    else:\n        return pd.Timestamp(row).strftime('%Y-%m-%d')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "50272e7d-c7e9-41d0-9fed-eb8378b9120a",
   "metadata": {
    "language": "python",
    "name": "cell159"
   },
   "outputs": [],
   "source": "merge_final[\"DATE_INVOICE_GL_DATE_CANONICAL\"] = merge_final[\"DATE_INVOICE_GL_DATE\"].apply(timestamp_To_Date)\nmerge_final[\"DATE_INVOICE_GL_DATE_CANONICAL\"].head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ed5ada42-1faf-4837-ac9c-e79f5b64572c",
   "metadata": {
    "language": "python",
    "name": "cell162"
   },
   "outputs": [],
   "source": "merge_final[\"RECEIPT_DATE\"].head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "be404ef7-3688-437b-a336-f92d4901a00b",
   "metadata": {
    "language": "python",
    "name": "cell161"
   },
   "outputs": [],
   "source": "merge_final[\"RECEIPT_DATE_CANONICAL\"] = merge_final[\"RECEIPT_DATE\"].apply(timestamp_To_Date)\nmerge_final[\"RECEIPT_DATE_CANONICAL\"].head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "176424e0-22fe-41f3-a3b0-9a2ff9f1fb85",
   "metadata": {
    "language": "python",
    "name": "cell163"
   },
   "outputs": [],
   "source": "merge_final[\"YYYYWK_MONTH_CANONICAL\"] = merge_final[\"YYYYWK_MONTH\"].apply(timestamp_To_Date)\nmerge_final[\"YYYYWK_MONTH_CANONICAL\"].head(100)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9be39259-057c-45b7-92bc-13761bae9b21",
   "metadata": {
    "language": "python",
    "name": "cell158"
   },
   "outputs": [],
   "source": "merge_final.drop([\"DATE_INVOICE_GL_DATE\", \"RECEIPT_DATE\", \"YYYYWK_MONTH\"], inplace=True, axis=1)\nmerge_final.rename(columns={\"DATE_INVOICE_GL_DATE_CANONICAL\":\"DATE_INVOICE_GL_DATE\", \"RECEIPT_DATE_CANONICAL\":\"RECEIPT_DATE\", \"YYYYWK_MONTH_CANONICAL\":\"YYYYWK_MONTH\"}, inplace=True)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a242b23f-034e-4a8c-8ea4-0e96a412f085",
   "metadata": {
    "language": "python",
    "name": "cell154"
   },
   "outputs": [],
   "source": "merge_final.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "366e6145-3092-43ba-a0e6-f63576a57f31",
   "metadata": {
    "language": "python",
    "name": "cell141",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "session.write_pandas(merge_final, \"PS_DOCUWARE_RAW_DATA_EXTRACTION\", auto_create_table=True, overwrite = True)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1e74561c-10a8-4638-9551-a32e13591bbb",
   "metadata": {
    "language": "python",
    "name": "cell53"
   },
   "outputs": [],
   "source": "raw_df = session.sql(\"SELECT * FROM RAC_RAPID_DEV.RUS_AIML.PS_DOCUWARE_RAW_DATA_EXTRACTION\").to_pandas()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "89e1b50e-4fc2-47b8-8367-c1ec5316f191",
   "metadata": {
    "language": "python",
    "name": "cell55"
   },
   "outputs": [],
   "source": "raw_df.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "47bf15ba-ad5d-42da-bd1f-5dfa827c6772",
   "metadata": {
    "language": "python",
    "name": "cell164"
   },
   "outputs": [],
   "source": "raw_df",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bda4fdec-bce5-4cd8-89f9-4a996a72cf0d",
   "metadata": {
    "name": "cell157",
    "collapsed": false
   },
   "source": "# Data Imputation and Feature Engineering to make Training Set"
  },
  {
   "cell_type": "code",
   "id": "664a1b8d-3316-4be3-ba53-bf31b21ffb16",
   "metadata": {
    "language": "python",
    "name": "cell156"
   },
   "outputs": [],
   "source": "#try:\n#Fetching from previous SPROC output table\nraw_df = session.sql(\"SELECT * FROM RAC_RAPID_DEV.RUS_AIML.PS_DOCUWARE_RAW_DATA_EXTRACTION\").to_pandas()\n\nnon_ts_numeric_cols = [\"PROBABILITY_OF_DELINQUENCY\", \"RICOH_CUSTOM_RISK_MODEL\"]\nnon_ts_categorical_cols = [\"OVERALL_BUSINESS_RISK\", \"PAYMENT_RISK_TRIPLE_A_RATING\", \"CONTRACT_LINE_ITEMS\"]\ncolumns_to_be_processed_later = non_ts_numeric_cols + non_ts_categorical_cols + [\"CUST_ACCOUNT_NUMBER\", \"LIFESPAN_MONTHS\", \"DAYS_TO_CHURN\"]\nfinalized_df_ohe_to_process = raw_df.groupby(\"CUST_ACCOUNT_NUMBER\")[columns_to_be_processed_later].first()\n\n# Imputation for Non Time Series columns\npofd_median = finalized_df_ohe_to_process[\"PROBABILITY_OF_DELINQUENCY\"].median()\nfinalized_df_ohe_to_process[\"PROBABILITY_OF_DELINQUENCY\"] = finalized_df_ohe_to_process[\"PROBABILITY_OF_DELINQUENCY\"].apply(lambda x:   float(pofd_median) if np.isnan(x) else x)\n\n#rcrm_mode = finalized_df_ohe_to_process[\"RICOH_CUSTOM_RISK_MODEL\"].mode()\ntemp=finalized_df_ohe_to_process[\"RICOH_CUSTOM_RISK_MODEL\"].mode().to_frame()\nrcrm_mode = temp.loc[temp.index[0], 'RICOH_CUSTOM_RISK_MODEL']\nfinalized_df_ohe_to_process[\"RICOH_CUSTOM_RISK_MODEL\"] = finalized_df_ohe_to_process[\"RICOH_CUSTOM_RISK_MODEL\"].apply(lambda x: float(rcrm_mode) if np.isnan(x) else x)\n\n# One Hot Encoding for Categorical variables OVERALL_BUSINESS_RISK and PAYMENT_RISK_TRIPLE_A_RATING\nfinalized_df_ohe_to_process = finalized_df_ohe_to_process.reset_index(drop=True)\n\ncategorical_cols = [\"OVERALL_BUSINESS_RISK\", \"PAYMENT_RISK_TRIPLE_A_RATING\"]\nfill_value = \"UNK\"\n\nfor col in categorical_cols:\n    finalized_df_ohe_to_process[col].fillna(fill_value, inplace=True)\n    finalized_df_ohe_to_process[col] = finalized_df_ohe_to_process[col].str.replace(\" \", \"_\", regex=False)\n    \n    if col == \"OVERALL_BUSINESS_RISK\":\n        col_abreviation = \"obr_\"\n    else:\n        col_abreviation = \"prtar_\"\n        \n    le_ohe = LabelEncoder()\n    ohe = OneHotEncoder(handle_unknown = \"ignore\")\n    enc_train = le_ohe.fit_transform(finalized_df_ohe_to_process[col]).reshape(finalized_df_ohe_to_process.shape[0],1)\n    ohe_train = ohe.fit_transform(enc_train)\n    le_ohe_name_mapping = dict(zip(le_ohe.classes_, le_ohe.transform(le_ohe.classes_)))\n    \n    enc_train = finalized_df_ohe_to_process[col].map(le_ohe_name_mapping).ravel().reshape(-1,1)\n    enc_train[np.isnan(enc_train)] = 9999\n\n    cols = [col_abreviation + str(x) for x in le_ohe_name_mapping.keys()]\n    finalized_df_ohe_to_process = pd.concat([finalized_df_ohe_to_process.reset_index(), pd.DataFrame.sparse.from_spmatrix(ohe_train, columns = cols)], axis = 1).drop([\"index\"], axis=1)\n    finalized_df_ohe_to_process.drop([col], axis = 1, inplace=True)\n\ncolumns_to_be_droped = non_ts_categorical_cols+non_ts_numeric_cols\nraw_df.drop(columns_to_be_droped, axis=1, inplace=True)\n\n# Target Encoding for CONTRACT_LINE_ITEMS\nfinalized_df_ohe_to_process[\"CONTRACT_LINE_ITEMS\"].fillna(\"NA\", inplace=True)\nfinalized_df_ohe_to_process[\"CONTRACT_LINE_ITEMS\"] = finalized_df_ohe_to_process[\"CONTRACT_LINE_ITEMS\"].str.replace(r\"\\\\d+x \", \"\", regex=True)\n\nfor i, row in finalized_df_ohe_to_process.iterrows():\n    t = row[\"CONTRACT_LINE_ITEMS\"]\n    arr = t.split(\"-\")\n    arr = [x.strip() for x in arr]\n    arr_s = sorted(arr)\n    key = \"-\".join([s for s in arr_s])\n    finalized_df_ohe_to_process.loc[i, \"CONTRACT_LINE_ITEMS\"] = key\n\nX_train = finalized_df_ohe_to_process.copy()\ny_train = finalized_df_ohe_to_process[\"LIFESPAN_MONTHS\"]\n\nenc = TargetEncoder(cols = [\"CONTRACT_LINE_ITEMS\"]).fit(X_train, y_train)\nX_train_encoded = enc.transform(X_train)\n\nnow = datetime.now()\ndate_string = now.strftime(\"%m-%d-%Y\")\n\n#encoder_filename = \"@RAC_RAPID_DEV.RUS_AIML.PS_DOCUWARE_CHURN/ps_docuware_target_encoder_object/ENC_CURRENT.joblib\"\n#encoder_filename_ar = \"@RAC_RAPID_DEV.RUS_AIML.PS_DOCUWARE_CHURN/ps_docuware_target_encoder_object/archive/ENC_\"+date_string+\".joblib\"\n\n#joblib.dump(enc,  encoder_filename)\n#joblib.dump(enc, encoder_filename_ar)\n\nimport_dir = sys._xoptions.get(\"snowflake_import_directory\")\nmodel_file = os.path.join(\"/tmp\", \"ENC_CURRENT.joblib.gz\")\ndump(enc, model_file)\n#session.file.put(model_file, \"@PS_DOCUWARE_CHURN\",overwrite=True)\nsession.file.put(model_file, \"@PS_DOCUWARE_CHURN/ps_docuware_target_encoder_object\",overwrite=True)\n\nmodel_file_ar = os.path.join(\"/tmp\", \"ENC_\"+date_string+\".joblib.gz\")\ndump(enc, model_file_ar)\nsession.file.put(model_file_ar, \"@PS_DOCUWARE_CHURN/ps_docuware_target_encoder_object/archive\",overwrite=True)\n\n# Imputation for Time Series columns\nts_columns = [\"CUST_ACCOUNT_NUMBER\", \"YYYYWK\", \"DOCUMENTS_OPENED\", \"USED_STORAGE__MB\", \"INVOICE_REVLINE_TOTAL\", \"ORIGINAL_AMOUNT_DUE\", \"FUNCTIONAL_AMOUNT\"]\nraw_df[\"transformed_YYYYWK\"] = raw_df[\"MONTH\"].apply(convert_date_to_yyyywk)\n#Impute missing YYYYWK with equivalent MONTH\nraw_df[\"YYYYWK\"].fillna(raw_df[\"transformed_YYYYWK\"], inplace=True)\nraw_df.drop(\"transformed_YYYYWK\", axis=1, inplace=True)\nts_df = raw_df[ts_columns]\nts_df = ts_df[ts_df['YYYYWK'].notna()]\nts_df['YYYYWK'] = ts_df['YYYYWK'].astype(int)\nts_df['CUST_ACCOUNT_NUMBER'] = ts_df['CUST_ACCOUNT_NUMBER'].astype(int)\nts_df.rename(columns={'USED_STORAGE__MB':'USED_STORAGE_MB'},inplace=True)\nts_df_sorted = ts_df.sort_values(['CUST_ACCOUNT_NUMBER','YYYYWK']).drop_duplicates()\n\nonly_features = ts_df_sorted.copy()\nonly_features = only_features.fillna(0)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9de36afe-e066-40ea-9efb-a106e741d18e",
   "metadata": {
    "language": "python",
    "name": "cell165"
   },
   "outputs": [],
   "source": "only_features",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "69e78ef2-8bdc-4ade-84c7-25fdf578ff8a",
   "metadata": {
    "language": "python",
    "name": "cell155"
   },
   "outputs": [],
   "source": "only_features.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1484a9cf-b6c3-4dea-814f-a92d2e20601e",
   "metadata": {
    "language": "python",
    "name": "cell41"
   },
   "outputs": [],
   "source": "lifespan_df = raw_df[['CUST_ACCOUNT_NUMBER', 'DAYS_TO_CHURN']]\nlifespan_df['CUST_ACCOUNT_NUMBER'] = lifespan_df['CUST_ACCOUNT_NUMBER'].astype(int)\nlifespan_df.drop_duplicates(inplace=True)\nlifespan_df.shape",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8b4754ef-48fa-478a-b92a-ee257e61741c",
   "metadata": {
    "language": "python",
    "name": "cell46"
   },
   "outputs": [],
   "source": "df_churn_cust = l1_cust_churned[[\"CUST_ACCOUNT_NUMBER\", \"CHURN_DATE\"]]\ndf_churn_cust['CHURN_YYYYWK_DATE'] = df_churn_cust['CHURN_DATE'].apply(convert_date_to_yyyywk)\ndf_churn_cust['CUST_ACCOUNT_NUMBER'] = df_churn_cust['CUST_ACCOUNT_NUMBER'].astype(int)\n#print(only_features.shape) # (14614, 7)\ndf_raw_churn = only_features.merge(df_churn_cust, on='CUST_ACCOUNT_NUMBER', how='inner')\n#print(df_raw_churn.shape) # (14614, 9)\nfinal_features = df_raw_churn[df_raw_churn['YYYYWK'] <= df_raw_churn['CHURN_YYYYWK_DATE']]\nprint(final_features.shape)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bc48b651-8783-4fef-8baa-2b45165b5b90",
   "metadata": {
    "language": "python",
    "name": "cell70"
   },
   "outputs": [],
   "source": "final_features.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "00bcb40c-ff35-4383-9e34-97e3b7f06b76",
   "metadata": {
    "language": "python",
    "name": "cell72"
   },
   "outputs": [],
   "source": "final_features_for_FE = final_features.drop(['CHURN_DATE', 'CHURN_YYYYWK_DATE'], axis=1)\n#print(final_features_for_FE.shape) # (5551, 7)\nfinal_features_for_FE = final_features_for_FE.merge(lifespan_df, on='CUST_ACCOUNT_NUMBER', how='inner')\n#print(final_features_for_FE.shape) # (5551, 8)\nfinal_features_for_FE.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c97c4556-f09c-4a7d-bdc4-c35fd3880e10",
   "metadata": {
    "language": "python",
    "name": "cell166"
   },
   "outputs": [],
   "source": "final_features_for_FE.shape",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ebb4cf9a-7d0a-41d8-b0a5-130fb58b5dc0",
   "metadata": {
    "language": "python",
    "name": "cell73"
   },
   "outputs": [],
   "source": "final_features_for_FE.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bc9f0c72-f9b5-4508-825e-e96d725c1844",
   "metadata": {
    "language": "python",
    "name": "cell99"
   },
   "outputs": [],
   "source": "print(X_train_encoded['CONTRACT_LINE_ITEMS'])\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4169d2d5-3457-4c5f-9c16-3baefed2236b",
   "metadata": {
    "name": "cell32",
    "collapsed": false
   },
   "source": "# Store time series and Non time series data into DB before feature engineering from TSFRESH"
  },
  {
   "cell_type": "code",
   "id": "6fad1f3c-f4a7-4a27-9841-f7f34f60c9ef",
   "metadata": {
    "language": "python",
    "name": "cell167"
   },
   "outputs": [],
   "source": "for col in X_train_encoded.columns:\n    if pd.api.types.is_sparse(X_train_encoded[col]):\n        X_train_encoded[col] = X_train_encoded[col].sparse.to_dense()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c8749f21-6c77-4c47-bbf7-21f6deb4294e",
   "metadata": {
    "language": "sql",
    "name": "cell177"
   },
   "outputs": [],
   "source": "WITH fi(CUST_ACCOUNT_NUMBER, YYYYWK) AS(\n    SELECT CUST_ACCOUNT_NUMBER, min(YYYYWK) AS YY FROM RUS_AIML.DOCUWARE_USAGE_JAPAN_V1_LATEST_V GROUP BY(CUST_ACCOUNT_NUMBER)\n)\n\nSELECT a.CUST_ACCOUNT_NUMBER, a.YYYYWK FROM fi a join RUS_AIML.PS_DOCUWARE_L1_CUST b on a.CUST_ACCOUNT_NUMBER = b.CUST_ACCOUNT_NUMBER where b.CHURNED_FLAG=True;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0b1667c3-2445-46c3-872c-d0f5dbcef847",
   "metadata": {
    "language": "python",
    "name": "cell181"
   },
   "outputs": [],
   "source": "all_usage = cell177.to_pandas()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e5c6bec8-b2cb-43d7-962b-01cdf47cd499",
   "metadata": {
    "language": "python",
    "name": "cell176"
   },
   "outputs": [],
   "source": "raw_df = session.sql(\"SELECT * FROM RAC_RAPID_DEV.RUS_AIML.PS_DOCUWARE_RAW_DATA_EXTRACTION\").to_pandas()\ndf_cust_earliest_date = raw_df[['CUST_ACCOUNT_NUMBER', 'FINAL_EARLIEST_DATE']]\ndf_cust_earliest_date.drop_duplicates(inplace=True)\ndf_cust_earliest_date['CUST_ACCOUNT_NUMBER'] = df_cust_earliest_date['CUST_ACCOUNT_NUMBER'].astype(int)\nall_usage['CUST_ACCOUNT_NUMBER'] = all_usage['CUST_ACCOUNT_NUMBER'].astype(int)\ndf_merged = pd.merge(df_cust_earliest_date, all_usage , on='CUST_ACCOUNT_NUMBER', how='inner')\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "89c58e61-a6e2-4aeb-8dab-7992893d2669",
   "metadata": {
    "language": "python",
    "name": "cell178"
   },
   "outputs": [],
   "source": "df_merged['CUST_ACCOUNT_NUMBER'] = df_merged['CUST_ACCOUNT_NUMBER'].astype(int)\nfinal_features_for_FE['CUST_ACCOUNT_NUMBER'] = final_features_for_FE['CUST_ACCOUNT_NUMBER'].astype(int)\nfinal_features_for_FE_trimmed = pd.DataFrame()\n\nfor ind,row in df_merged.iterrows():   \n    t = final_features_for_FE[ final_features_for_FE['CUST_ACCOUNT_NUMBER'] == row['CUST_ACCOUNT_NUMBER'] ]\n    t['YYYYWK'] = t['YYYYWK'].astype(int)\n    yyyywk_date = convert_yyyywk_to_actual_mid_date(row['YYYYWK'])\n    \n    row['YYYYWK'] = int(row['YYYYWK'])\n    tt = t[ t['YYYYWK'] >= row['YYYYWK'] ]\n    tt['DAYS_TO_CHURN'] = tt['DAYS_TO_CHURN'] - (pd.to_datetime(yyyywk_date) - pd.to_datetime(row['FINAL_EARLIEST_DATE'])).days\n    final_features_for_FE_trimmed = pd.concat([tt, final_features_for_FE_trimmed], axis=0, ignore_index=True)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9ec6ede2-cdb8-48b9-8ef1-a54e461deaaf",
   "metadata": {
    "language": "python",
    "name": "cell182"
   },
   "outputs": [],
   "source": "final_features_for_FE_trimmed",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9a99113a-496c-4645-9127-a2fa78e43459",
   "metadata": {
    "language": "python",
    "name": "cell179"
   },
   "outputs": [],
   "source": "final_features_for_FE_trimmed.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "25decb73-b9fa-4488-8d99-7e55c6fc5bdb",
   "metadata": {
    "language": "python",
    "name": "cell43"
   },
   "outputs": [],
   "source": "session.write_pandas(X_train_encoded, \"PS_DOCUWARE_RAW_X_TRAIN_ENCODED_DATA_BEFORE_TSFRESH\", auto_create_table=True, overwrite = True)\nsession.write_pandas(final_features_for_FE_trimmed, \"PS_DOCUWARE_RAW_DATA_BEFORE_TSFRESH\", auto_create_table=True, overwrite = True)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d1316a04-aa64-454d-afdf-6689b2dd1bb6",
   "metadata": {
    "name": "cell56"
   },
   "source": "# Starting TSFRESH API"
  },
  {
   "cell_type": "code",
   "id": "5dc0ae5f-ecee-4554-821e-a79e24cc6dca",
   "metadata": {
    "language": "python",
    "name": "cell42"
   },
   "outputs": [],
   "source": "#ts_comprehensive_df = time_series_ts_fresh_features(only_features)\nts_comprehensive_df, final_ts_age  = engineer_timeseries_cols_using_tsfresh(final_features_for_FE_trimmed)\n\n#ts_comprehensive_df = session.sql(\"SELECT * FROM RAC_RAPID_DEV.RUS_AIML.PS_DOCUWARE_ONLY_TS_DF\").to_pandas()\n\n    \n#except Exception as e: \n#    print(\"FAIL(Post Processing)!\" + \" Error: \" + str(e))\nts_comprehensive_df = ts_comprehensive_df.reset_index(drop=True)\nfinal_ts_age = final_ts_age.reset_index(drop=True)\n\nfinal_ts_df = pd.concat([ts_comprehensive_df, final_ts_age], axis=1, ignore_index=True)\n#session.write_pandas(final_ts_df, \"PS_DOCUWARE_TSFRESH_FEATURES_WITH_AGE\", auto_create_table=True, overwrite = True)\n\nall_columns = ts_comprehensive_df.columns.tolist()+final_ts_age.columns.tolist()\nfinal_ts_df.columns = all_columns\nfinal_ts_df.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e62ec712-7855-497f-a445-fc9f0c697e21",
   "metadata": {
    "language": "python",
    "name": "cell83"
   },
   "outputs": [],
   "source": "final_ts_age",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a07721c3-e9b1-4b8a-8085-3c7dcc60be9f",
   "metadata": {
    "language": "python",
    "name": "cell84"
   },
   "outputs": [],
   "source": "for col in final_ts_df.columns:\n    if re.search(\"^DAYS\", col):\n        print(col)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "056d029c-dcb0-4365-b7ff-6fed799328f5",
   "metadata": {
    "language": "python",
    "name": "cell38"
   },
   "outputs": [],
   "source": "ts_comprehensive_df = final_ts_df.copy()\nts_comprehensive_df.shape",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "173ce17f-bd3c-4b07-aa54-bb3b8f78c7eb",
   "metadata": {
    "language": "python",
    "name": "cell39"
   },
   "outputs": [],
   "source": "# Check if it contains CUST_ACCOUNT_NUMBER related TSFRESH features\n\nfor col in ts_comprehensive_df.columns:\n    if re.search(\"^CUST_ACCOUNT_NUMBER_\", col):\n        print(col)\n    if re.search(\"^DAYS\", col):\n        print(col)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c6e727bb-c2b7-4d21-b9a6-82ff001de78c",
   "metadata": {
    "language": "python",
    "name": "cell37",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Check first two words of all columns generated by TSFRESH\nprefix=set()\n\nfor col in ts_comprehensive_df.columns:\n    prefix.add((col.split('_')[0], col.split('_')[1]))",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ddf530b0-dc2d-4e64-bf30-0b524a00a2bc",
   "metadata": {
    "language": "python",
    "name": "cell12"
   },
   "outputs": [],
   "source": "print(prefix)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "07e9a0e5-dad2-402a-9b8d-65e34e193d05",
   "metadata": {
    "name": "cell54",
    "collapsed": false
   },
   "source": "# Storing Training Data after Feature Engineering and before Training"
  },
  {
   "cell_type": "code",
   "id": "a37b251e-8ba0-46a3-8aaf-492e9b580720",
   "metadata": {
    "language": "python",
    "name": "cell36"
   },
   "outputs": [],
   "source": "ts_comprehensive_df[\"CUST_ACCOUNT_NUMBER\"] = ts_comprehensive_df[\"CUST_ACCOUNT_NUMBER\"].astype(int)\nX_train_encoded[\"CUST_ACCOUNT_NUMBER\"] = X_train_encoded[\"CUST_ACCOUNT_NUMBER\"].astype(int)\nX_train_encoded = X_train_encoded.reset_index(drop=True)\nts_comprehensive_df = ts_comprehensive_df.reset_index(drop=True)\ncomprehensive_imputed_df = pd.merge(ts_comprehensive_df, X_train_encoded, on=\"CUST_ACCOUNT_NUMBER\", how=\"inner\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9cb47cef-abf4-4bbc-8c3a-8664fb682fb6",
   "metadata": {
    "language": "python",
    "name": "cell91"
   },
   "outputs": [],
   "source": "ts_comprehensive_df.shape, X_train_encoded.shape, comprehensive_imputed_df.shape",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4339a5b5-58dd-4ae1-b473-5fe3f1cd8079",
   "metadata": {
    "language": "python",
    "name": "cell89"
   },
   "outputs": [],
   "source": "for col in ts_comprehensive_df.columns:\n    if re.search(\"^DAYS\", col):\n        print(col)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "11d39518-4346-4625-90e1-e78e31e508c7",
   "metadata": {
    "language": "python",
    "name": "cell90"
   },
   "outputs": [],
   "source": "for col in comprehensive_imputed_df.columns:\n    if re.search(\"^DAYS\", col):\n        print(col)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3a0f78b5-f8d3-4dfd-8712-82d369534624",
   "metadata": {
    "language": "python",
    "name": "cell88"
   },
   "outputs": [],
   "source": "for col in comprehensive_imputed_df.columns:\n    if pd.api.types.is_sparse(comprehensive_imputed_df[col]):\n        comprehensive_imputed_df[col] = comprehensive_imputed_df[col].sparse.to_dense()\n\nsession.write_pandas(comprehensive_imputed_df, \"PS_DOCUWARE_IMPUTED_DATA\", auto_create_table=True, overwrite = True)\n#session.write_pandas(comprehensive_imputed_df, \"PS_DOCUWARE_IMPUTED_DATA_266\", auto_create_table=True, overwrite = True)\n\nprint(\"Successfuly created table PS_DOCUWARE_IMPUTED_DATA\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c6fed6f2-c4fc-4f25-861d-20b11b20b475",
   "metadata": {
    "language": "python",
    "name": "cell10"
   },
   "outputs": [],
   "source": "ts_comprehensive_df.shape\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "aea1afa8-ca44-4958-8fe4-29ef5135696a",
   "metadata": {
    "language": "python",
    "name": "cell13"
   },
   "outputs": [],
   "source": "comprehensive_imputed_df.shape",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0292dfe0-0ede-4948-b694-6d9058112deb",
   "metadata": {
    "language": "python",
    "name": "cell86"
   },
   "outputs": [],
   "source": "for col in ts_comprehensive_df.columns:\n    if re.search(\"^DAYS\", col):\n        print(col)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "92071196-ea2c-43ef-b02f-252dbe77c914",
   "metadata": {
    "language": "python",
    "name": "cell87"
   },
   "outputs": [],
   "source": "for col in X_train_encoded.columns:\n    if re.search(\"^DAYS\", col):\n        print(col)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ead33bef-c88a-4aa4-8e60-81b21a6b71d7",
   "metadata": {
    "language": "python",
    "name": "cell85"
   },
   "outputs": [],
   "source": "for col in comprehensive_imputed_df.columns:\n    if re.search(\"^DAYS\", col):\n        print(col)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e03e5d5d-05fe-4144-8772-499ed108e043",
   "metadata": {
    "language": "python",
    "name": "cell81"
   },
   "outputs": [],
   "source": "# Check first two words of all columns generated by TSFRESH\nprefix=set()\n\nfor col in comprehensive_imputed_df.columns:\n    prefix.add((col.split('_')[0], col.split('_')[1]))\n    prefix.add(col.split('_')[0])",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1c2ddb7e-9f90-43f7-af8c-251ab00b2399",
   "metadata": {
    "language": "python",
    "name": "cell82"
   },
   "outputs": [],
   "source": "prefix",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "091688e3-6f25-40c6-9b24-c8f70cfff760",
   "metadata": {
    "name": "cell57"
   },
   "source": "# Training using XGBoost Regression"
  },
  {
   "cell_type": "code",
   "id": "591568f5-0b05-4a2b-8712-9d443965282e",
   "metadata": {
    "language": "python",
    "name": "cell198"
   },
   "outputs": [],
   "source": "",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f9788ab3-3537-47bb-884b-53846d7406e0",
   "metadata": {
    "language": "python",
    "name": "cell100"
   },
   "outputs": [],
   "source": "comprehensive_imputed_df = session.sql(\"SELECT * FROM RUS_AIML.PS_DOCUWARE_IMPUTED_DATA\").to_pandas()\ncomprehensive_imputed_df = comprehensive_imputed_df.replace([np.inf, -np.inf], 0)\ncomprehensive_imputed_df = comprehensive_imputed_df.fillna(0)\n\nfor col in comprehensive_imputed_df.columns:\n    comprehensive_imputed_df[col] = pd.to_numeric(comprehensive_imputed_df[col], errors=\"coerce\").astype(float)\n\n# comprehensive_imputed_o_df = pd.series(comprehensive_imputed_df)\n# comprehensive_imputed_df = pd.to_numeric(comprehensive_imputed_o_df, errors=\"coerce\")\n# comprehensive_imputed_df = comprehensive_imputed_df.to_frame()\n\n\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9e529ed9-e142-43b8-b9f8-f380850f4a4a",
   "metadata": {
    "language": "python",
    "name": "cell101",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "cust_churn_df = comprehensive_imputed_df[[\"CUST_ACCOUNT_NUMBER\",\"DAYS_TO_CHURN\"]]\ncust_churn_df.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6142e7f7-876a-4fff-a501-2df0bc65a619",
   "metadata": {
    "language": "python",
    "name": "cell168",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "all_columns = comprehensive_imputed_df.columns\nfor cols in all_columns:\n    if re.search(\"^CUST_ACCOUNT_NUMBER\" , cols):\n        print(cols)\n        ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ec37c080-e714-443c-bf26-4a67461d6af6",
   "metadata": {
    "language": "python",
    "name": "cell103",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "cust_churn_df.drop_duplicates(inplace=True)\ncust_churn_df.shape",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c5e4ee3f-737b-4ae3-ba46-0c37f2a251a6",
   "metadata": {
    "language": "python",
    "name": "cell104",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "cust_churn_df.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "385f87fb-11db-4241-80d5-69c5bb94f697",
   "metadata": {
    "language": "python",
    "name": "cell102",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Stratified Sampling\nstratified_df = pd.DataFrame()\n\nlabel_count=1\nfor i in range(365, 1461, 365):\n    XX = cust_churn_df[((i-365) < cust_churn_df[\"DAYS_TO_CHURN\"]) & (cust_churn_df[\"DAYS_TO_CHURN\"] <= i)]\n    XX[\"SAMPLE\"] = label_count\n    stratified_df = pd.concat([stratified_df, XX], axis=0, ignore_index=True)\n    label_count+=1\n    #print(\"For \", (i-365)+1, \" To \", i , \" Total Counts = \", XX.shape[0])\n    if i==1460:\n        XX = cust_churn_df[1460 < cust_churn_df[\"DAYS_TO_CHURN\"]]\n        XX[\"SAMPLE\"] = label_count\n        stratified_df = pd.concat([stratified_df, XX], axis=0, ignore_index=True)\n        #print(\"For \", 1460+1, \" To upper limit Total Counts = \", (1460 < data[\"DAYS_TO_CHURN\"]).sum())",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "72535609-7573-4fac-a161-cec99b4c2a87",
   "metadata": {
    "language": "python",
    "name": "cell128",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "stratified_df[\"NO_OF_RENEWALS\"] = stratified_df[\"SAMPLE\"]-1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f3f7dd8c-b2bf-495c-81ba-dd66eb8986b7",
   "metadata": {
    "language": "python",
    "name": "cell105",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "stratified_df[\"SAMPLE\"].value_counts()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "34255f3e-e685-454d-b4de-37a0233cc25f",
   "metadata": {
    "language": "python",
    "name": "cell129",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "stratified_df[\"NO_OF_RENEWALS\"].value_counts()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "34b0eee2-5099-4605-b044-d586d291e4a8",
   "metadata": {
    "language": "python",
    "name": "cell108",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "stratified_df.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5d12ff90-9d23-4225-9603-3b7d1a5c44c3",
   "metadata": {
    "language": "python",
    "name": "cell106",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "stratified_df = stratified_df[stratified_df['SAMPLE']!=5]\nfeatures = stratified_df.drop([\"DAYS_TO_CHURN\", \"SAMPLE\"], axis=1)\ny = stratified_df[\"SAMPLE\"]",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b53142b7-1b3e-41f5-8bcb-1b819b3c5084",
   "metadata": {
    "language": "python",
    "name": "cell192",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "features",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7115d3d1-a5b8-46a0-ae35-ae1dd40387c8",
   "metadata": {
    "language": "python",
    "name": "cell191",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "y",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "df96fa26-ecff-4839-92fa-e036d8ed7b3e",
   "metadata": {
    "language": "python",
    "name": "cell107",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "X_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.2, random_state=42, shuffle=True, stratify=y)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "46a01239-9a33-4d7f-97d6-9a4fa24ee7fb",
   "metadata": {
    "language": "python",
    "name": "cell109",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "X_train.shape, X_test.shape, y_train.shape, y_test.shape",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e3d54964-85b0-4584-bfaa-ce67b8afda4b",
   "metadata": {
    "language": "python",
    "name": "cell110",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "y_train.value_counts()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "18077aa3-2b3e-4495-a37e-1aef1c4f7b3d",
   "metadata": {
    "language": "python",
    "name": "cell111",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "y_test.value_counts()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7fa09f68-35d5-41f0-b55f-47d2971b3c17",
   "metadata": {
    "language": "python",
    "name": "cell112",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "X_test.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6e885d7a-8de0-4603-8485-9c2c696cfcee",
   "metadata": {
    "language": "python",
    "name": "cell113",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "type(X_train), type(X_test), type(y_train), type(y_test)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "01e9923b-a6ee-45f6-b43b-5bab2b177529",
   "metadata": {
    "language": "python",
    "name": "cell114",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "comprehensive_imputed_df.shape",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "047d28fa-225c-4d34-aed4-2a8e0110b0a9",
   "metadata": {
    "language": "python",
    "name": "cell197"
   },
   "outputs": [],
   "source": "comprehensive_imputed_df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a9d0b202-e623-4855-8eba-33eae0ae2fcf",
   "metadata": {
    "language": "python",
    "name": "cell115",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "X_train_all_cols = pd.merge(comprehensive_imputed_df, X_train, how='inner', on='CUST_ACCOUNT_NUMBER')\nX_train_all_cols.shape",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "691786db-ffd1-4361-8bb1-c2c443a4bca0",
   "metadata": {
    "language": "python",
    "name": "cell116",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "X_test_all_cols = pd.merge(comprehensive_imputed_df, X_test, how='inner', on='CUST_ACCOUNT_NUMBER')\nX_test_all_cols.shape",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "add708fe-f990-44cd-9615-f122a0793496",
   "metadata": {
    "language": "python",
    "name": "cell117",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "train_X = X_train_all_cols.drop([\"CUST_ACCOUNT_NUMBER\",\"LIFESPAN_MONTHS\",\"DAYS_TO_CHURN\", \"DAYS_REMAINING\"], axis=1) # Let cluster be in training\ntrain_y = X_train_all_cols[\"DAYS_REMAINING\"]",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a6866401-320f-49c8-9085-2c1f3c444497",
   "metadata": {
    "language": "python",
    "name": "cell118",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "test_X = X_test_all_cols.drop([\"CUST_ACCOUNT_NUMBER\",\"LIFESPAN_MONTHS\",\"DAYS_TO_CHURN\", \"DAYS_REMAINING\"], axis=1) # Let cluster be in training\ntest_y = X_test_all_cols[\"DAYS_REMAINING\"]",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d0a5af01-1b4f-418e-af31-564f95f8e8a7",
   "metadata": {
    "language": "python",
    "name": "cell119",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "train_X.shape, train_y.shape, test_X.shape, test_y.shape",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f152e552-679c-4e21-a496-6826b5f85091",
   "metadata": {
    "language": "python",
    "name": "cell120",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "type(train_X), type(test_X), type(train_y), type(test_y)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c6cfc2fe-6ed4-4330-8071-1281dbe5a302",
   "metadata": {
    "language": "python",
    "name": "cell205"
   },
   "outputs": [],
   "source": "import numpy as np\nnp.int = int\n\n#above code to resolve \n\"\"\"AttributeError: module 'numpy' has no attribute 'int'. `np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\"\"\"",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e974b800-3696-4cab-870c-f9a2cc6d144d",
   "metadata": {
    "language": "python",
    "name": "Sproc_4",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# #try:\n# #Fetching from previous SPROC output table\n# comprehensive_imputed_df = session.sql(\"SELECT * FROM RUS_AIML.PS_DOCUWARE_IMPUTED_DATA\").to_pandas()\n# comprehensive_imputed_df = comprehensive_imputed_df.replace([np.inf, -np.inf], 0)\n# comprehensive_imputed_df = comprehensive_imputed_df.fillna(0)\n\n# for col in comprehensive_imputed_df.columns:\n#     comprehensive_imputed_df[col] = pd.to_numeric(comprehensive_imputed_df[col], errors=\"coerce\").astype(float)\n\n# # comprehensive_imputed_o_df = pd.series(comprehensive_imputed_df)\n# # comprehensive_imputed_df = pd.to_numeric(comprehensive_imputed_o_df, errors=\"coerce\")\n# # comprehensive_imputed_df = comprehensive_imputed_df.to_frame()\n\n# # Stratified Sampling\n# stratified_df = pd.DataFrame()\n\n# comprehensive_imputed_df[[\"CUST_ACCOUNT_NUMBER\", \"DAYS_TO_CHURN\"]]\n\n# label_count=1\n# for i in range(365, 1461, 365):\n#     XX = comprehensive_imputed_df[((i-365) < comprehensive_imputed_df[\"DAYS_TO_CHURN\"]) & (comprehensive_imputed_df[\"DAYS_TO_CHURN\"] <= i)]\n#     #XX[\"SAMPLE\"] = label_count\n#     stratified_df = pd.concat([stratified_df, XX], axis=0, ignore_index=True)\n#     #label_count+=1\n#     #print(\"For \", (i-365)+1, \" To \", i , \" Total Counts = \", XX.shape[0])\n#     if i==1460:\n#         XX = comprehensive_imputed_df[1460 < comprehensive_imputed_df[\"DAYS_TO_CHURN\"]]\n#         XX[\"SAMPLE\"] = label_count\n#         stratified_df = pd.concat([stratified_df, XX], axis=0, ignore_index=True)\n#         #print(\"For \", 1460+1, \" To upper limit Total Counts = \", (1460 < data[\"DAYS_TO_CHURN\"]).sum())\n\n\n#stratified_df[\"LOG_OF_MONTHS_TO_CHURN\"] = np.log(stratified_df[\"LIFESPAN_MONTHS\"])\n\n# Stratified Sampling\n#features = stratified_df.drop([\"CUST_ACCOUNT_NUMBER\",\"LIFESPAN_MONTHS\",\"DAYS_TO_CHURN\", \"SAMPLE\"], axis=1)\n# features = comprehensive_imputed_df.drop([\"CUST_ACCOUNT_NUMBER\",\"LIFESPAN_MONTHS\",\"DAYS_TO_CHURN\", \"DAYS_REMAINING\"], axis=1) # Let cluster be in training\n# y = comprehensive_imputed_df[\"DAYS_REMAINING\"]\n\n# 20/80 Split\n# X_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.2, random_state=42, shuffle=True)#, stratify=y)\n#y_train = X_train[\"LOG_OF_MONTHS_TO_CHURN\"]\n#y_test = X_test[\"LOG_OF_MONTHS_TO_CHURN\"]\n\n#X_train.drop(\"LOG_OF_MONTHS_TO_CHURN\", axis=1, inplace=True)\n#X_test.drop(\"LOG_OF_MONTHS_TO_CHURN\", axis=1, inplace=True)\n\n# Training\n\nparam_grid = {\"learning_rate\": Real(0.01, 1.0, \"uniform\"),\n             \"max_depth\": Integer(2, 12),\n             \"subsample\": Real(0.1, 1.0, \"uniform\"),\n             \"colsample_bytree\": Real(0.1, 1.0, \"uniform\"), # subsample ratio of columns by tree\n             \"reg_lambda\": Real(1e-9, 100., \"uniform\"), # L2 regularization\n             \"reg_alpha\": Real(1e-9, 100., \"uniform\"), # L1 regularization\n             \"n_estimators\": Integer(20, 3000)\n}\n\nxgb_model = xgb.XGBRegressor(tree_method=\"gpu_hist\", random_state=10)\n\nbayes_search = BayesSearchCV(\n        estimator=xgb_model, \n        search_spaces=param_grid, \n        scoring=\"neg_mean_squared_error\", \n        cv=3,\n        n_iter=20,\n        n_jobs=-1,\n        verbose=3,\n        random_state=0)\n\nprint(\"Training Starts\")\n\nbayes_search.fit(train_X, train_y)\n\nprint(\"Training Finishes\")\n\nbest_models = bayes_search.best_estimator_\n\n#y_pred = best_models.predict(X_test)\n#rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n\nimport time\nimport datetime\nts = time.time()\ntime_of_day = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d::%H:%M:%S')\n\nprint(\"Writing model into Staging Archive\")\n#import_dir = sys._xoptions.get(\"snowflake_import_directory\")\nmodel_file = os.path.join(\"/tmp\", \"xgb.joblib.gz\")\ndump(best_models, model_file)\nsession.file.put(model_file, \"@PS_DOCUWARE_CHURN/ps_docuware_churn_model\",overwrite=True)\n\nprint(\"Writing model into Staging\")\nmodel_file = os.path.join(\"/tmp\", \"xgb.\"+str(time_of_day)+\".joblib.gz\")\ndump(best_models, model_file)\nsession.file.put(model_file, \"@PS_DOCUWARE_CHURN/ps_docuware_churn_model/archive\",overwrite=True)\n\nprint(\"Successfuly trained the model and stored\" )   \n#except Exception as e: \n#print(\"FAIL(Post Processing)!\" + \" Error: \" + str(e))",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c91bc795-c622-4afe-bf47-4e7d140c1ab1",
   "metadata": {
    "name": "cell96",
    "collapsed": false
   },
   "source": "# Test for churned customers"
  },
  {
   "cell_type": "code",
   "id": "febd5c75-05ec-4783-8c78-d04089f7d09e",
   "metadata": {
    "language": "python",
    "name": "cell121"
   },
   "outputs": [],
   "source": "# comprehensive_imputed_df.loc[test_X.index,\"CUST_ACCOUNT_NUMBER\"].astype(str).unique()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "00b35d40-fae6-4a6c-81c9-56ffa58b6170",
   "metadata": {
    "language": "python",
    "name": "cell130"
   },
   "outputs": [],
   "source": "X_test_all_cols[ X_test_all_cols[\"DAYS_REMAINING\"] == 0]",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "46f0399f-0026-4764-b494-5446a6e34295",
   "metadata": {
    "language": "python",
    "name": "cell122",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "last_rows_X_test = X_test_all_cols[ X_test_all_cols[\"DAYS_REMAINING\"] == 0]",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bc161da3-935c-4ff4-a764-2209c457837c",
   "metadata": {
    "language": "python",
    "name": "cell123",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "last_rows_X_test[[\"CUST_ACCOUNT_NUMBER\", \"DAYS_REMAINING\"]].index",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d9d5826c-61a7-41e8-9392-eb86fb00305f",
   "metadata": {
    "language": "python",
    "name": "cell124",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "test_25_X = last_rows_X_test.drop([\"CUST_ACCOUNT_NUMBER\",\"LIFESPAN_MONTHS\",\"DAYS_TO_CHURN\", \"DAYS_REMAINING\"], axis=1) # Let cluster be in training\ntest_25_y = last_rows_X_test[\"DAYS_REMAINING\"]",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "64f0e873-4c56-4446-9b0a-a2c84cd09486",
   "metadata": {
    "language": "python",
    "name": "cell131",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "test_25_X[\"NO_OF_RENEWALS\"]",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ed2fe790-8dde-44df-8829-4b046271d209",
   "metadata": {
    "language": "python",
    "name": "cell125",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "test_25_X.shape, test_25_y.shape",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1dc40cbf-2a96-4a5c-9ee4-c24dad56a45a",
   "metadata": {
    "language": "python",
    "name": "cell126",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "test_25_y",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "56d9f2ce-d4b0-4fc7-b1d5-aff2fd7b9b47",
   "metadata": {
    "language": "python",
    "name": "cell127",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Inferencing\ny_pred = best_models.predict(test_25_X)\nremaining_months = y_pred/30\nprint(remaining_months.shape)\n\nactual_remaining = test_25_y/30\nfinal_test_predicted_df = pd.DataFrame({\n    \"CUST_ACCOUNT_NUMBER\": last_rows_X_test.loc[test_25_X.index,\"CUST_ACCOUNT_NUMBER\"].astype(str),\n    \"PREDICTED_MONTHS_REMAINING\": remaining_months,\n    \"ACTUAL_MONTH_REMAINING\": actual_remaining,\n    \"RESIDUAL\": abs(remaining_months-actual_remaining)\n})\n\nfinal_test_predicted_df.head(50)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "10bd622c-e196-44e8-aca1-3c9c03d9ca70",
   "metadata": {
    "language": "python",
    "name": "cell95",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Load Training data\n# comprehensive_imputed_df = session.sql(\"SELECT * FROM RUS_AIML.PS_DOCUWARE_IMPUTED_DATA\").to_pandas()\n# comprehensive_imputed_df = comprehensive_imputed_df.replace([np.inf, -np.inf], 0)\n# comprehensive_imputed_df = comprehensive_imputed_df.fillna(0)\n\n# for col in comprehensive_imputed_df.columns:\n#     comprehensive_imputed_df[col] = pd.to_numeric(comprehensive_imputed_df[col], errors=\"coerce\").astype(float)\n\n# Stratified Sampling\n#features = stratified_df.drop([\"CUST_ACCOUNT_NUMBER\",\"LIFESPAN_MONTHS\",\"DAYS_TO_CHURN\", \"SAMPLE\"], axis=1)\n# features = comprehensive_imputed_df.drop([\"CUST_ACCOUNT_NUMBER\",\"LIFESPAN_MONTHS\",\"DAYS_TO_CHURN\", \"DAYS_REMAINING\"], axis=1) # Let cluster be in training\n# y = comprehensive_imputed_df[\"DAYS_REMAINING\"]\n\n# # 20/80 Split\n# X_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.2, random_state=42, shuffle=True)#, stratify=y)\n\n# # Load model_file\n# model_file = os.path.join('/tmp', 'xgb.joblib.gz')\n# session.file.get(\"@PS_DOCUWARE_CHURN/ps_docuware_churn_model/xgb.joblib.gz\", \"/tmp\")\n# best_models = load(model_file)\n\n# # Split XTrain,Ytrain\n\n\n# Inferencing\ny_pred = best_models.predict(test_X)\nremaining_months = y_pred/30\nprint(remaining_months.shape)\n\nactual_remaining = test_y/30\nfinal_test_predicted_df = pd.DataFrame({\n    \"CUST_ACCOUNT_NUMBER\": comprehensive_imputed_df.loc[test_X.index,\"CUST_ACCOUNT_NUMBER\"].astype(str),\n    \"PREDICTED_MONTHS_REMAINING\": remaining_months,\n    \"ACTUAL_MONTH_REMAINING\": actual_remaining,\n    \"RESIDUAL\": abs(remaining_months-actual_remaining)\n})\n\nfinal_test_predicted_df.head(796)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7f3e6c0b-ef0f-4a6c-a7b4-162c6b0e3926",
   "metadata": {
    "language": "python",
    "name": "cell207"
   },
   "outputs": [],
   "source": "final_test_predicted_df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5fb82ff7-817c-4408-be03-42d125e5c84c",
   "metadata": {
    "language": "python",
    "name": "cell206"
   },
   "outputs": [],
   "source": "",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c7c646ca-d8c6-45cb-b99d-c370357531fb",
   "metadata": {
    "language": "python",
    "name": "cell97",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Feature Importance Scores\nimportance = best_models.get_booster().get_score(importance_type='gain')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c092e219-ddd1-4d17-952d-c3fc47d355de",
   "metadata": {
    "language": "python",
    "name": "cell98",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "importance_df = pd.DataFrame(importance.items(), columns=['Feature', 'Score'])\nimportance_df.head(287)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9637c57c-9bfa-4f1a-a5b3-8e18869f28ff",
   "metadata": {
    "name": "cell58",
    "collapsed": false
   },
   "source": "# Plot of Important Features ranked by XGBoost algorithm"
  },
  {
   "cell_type": "code",
   "id": "e223ca92-a15a-492c-8334-df9395c5bd1a",
   "metadata": {
    "language": "python",
    "name": "cell204"
   },
   "outputs": [],
   "source": "importance_df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "90aef8b7-c211-430c-9e03-23d6fc29b8b7",
   "metadata": {
    "language": "python",
    "name": "cell44",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "plt.figure(figsize=(40,30))\nxgb.plot_importance(best_models, max_num_features=20)\n#plt.savefig('C:/My Documents/work/Projects/Short Term Goal 2 - Customer Churn Prediction/ML Modeling Phase/Overall_Model_Importance_16Apr_2025.png')\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4be680d4-2c65-4a6e-be3b-1066d7447177",
   "metadata": {
    "name": "cell59"
   },
   "source": "# Data extrcation of Live Customers for Inferencing"
  },
  {
   "cell_type": "code",
   "id": "3c208c26-ebe4-4506-a524-b204f697bb80",
   "metadata": {
    "language": "python",
    "name": "RepeatImputationMissingUsageData"
   },
   "outputs": [],
   "source": "#Code to impute missing usage data for first half of 2023\nusage_latest = session.sql(\"SELECT * FROM RUS_AIML.DOCUWARE_USAGE_JAPAN_V1_LATEST_V\").to_pandas()\n\nusage_latest['CONTRACT_START'] = pd.to_datetime(usage_latest['CONTRACT_START'])\nusage_latest['CHURN_DATE']= pd.to_datetime(usage_latest['CHURN_DATE'])\n\n#Focus only on Contract Start Date >= ‘2020-01-01’\nusageFIX = usage_latest[usage_latest['CONTRACT_START']>= '2020-01-01' ]\n\n# Active -  If contract start date <= 2022-12-31  for active then we need to add weekly usage numbers ( average of last 10 for numerical)\nusageFIXActive = usageFIX[(usageFIX['CONTRACT_START']<= '2022-12-31') & (usageFIX['CHURNED_FLAG']== False) & (usageFIX['YYYYWK'] <= 202252) ]\n\nidx = usageFIXActive.groupby('CUST_ACCOUNT_NUMBER')['YYYYWK'].idxmax()\nmax_scores = usageFIXActive.loc[idx]\ndf_duplicated = pd.DataFrame(np.repeat(max_scores.values, repeats=25, axis=0), columns=max_scores.columns)\ndf_duplicated= df_duplicated.sort_values(by = 'CUST_ACCOUNT_NUMBER')\n\n#range of YYYYWK missing data\nrecurring_range = []\n\nfor i in range(1,26):\n\n    if i < 10:\n        month_date = str(2023)+\"0\"+str(i)\n    else:\n        month_date = str(2023)+str(i)\n    recurring_range.append(month_date)\n\n# Calculate how many times the range needs to repeat\nnum_repeats = len(max_scores)    #len(df) // len(recurring_range) + 1\n\n# Create the new column values by repeating the range and truncating\nnew_column = np.tile(recurring_range, num_repeats)[:len(df_duplicated)]\n\n# Replace the column\ndf_duplicated['YYYYWK'] = new_column\n\n# Active account imputations\nActiveAccts = df_duplicated\n\n#End Active customer imputation\n\n#Churned Customer imputation\n\n# Churned Customers part 1    If contract start date <= 2022-12-31  and churned date after > 2022-12-31 then add in usage for wks between 202301-202325\nusageFIXChurned1 = usageFIX[(usageFIX['CONTRACT_START']<= '2022-12-31') & (usageFIX['CHURNED_FLAG']== True) &  (usageFIX['CHURN_DATE'] > '2023-06-24' ) & (usageFIX['YYYYWK'] <= 202252)   ]\n\nidx = usageFIXChurned1.groupby('CUST_ACCOUNT_NUMBER')['YYYYWK'].idxmax()\nmax_scores = usageFIXChurned1.loc[idx]\ndf_duplicated = pd.DataFrame(np.repeat(max_scores.values, repeats=25, axis=0), columns=max_scores.columns)\ndf_duplicated.sort_values(by = 'CUST_ACCOUNT_NUMBER')\n\n# Calculate how many times the range needs to repeat\nnum_repeats = len(max_scores)   #len(df) // len(recurring_range) + 1\n\n# Create the new column values by repeating the range and truncating\nnew_column = np.tile(recurring_range, num_repeats)[:len(df_duplicated)]\n\n# Replace the column\ndf_duplicated['YYYYWK'] = new_column\n\n# save imputations for part 1 of churned customers\nchurned1 = df_duplicated\n\n# end churned customer part1 \n\n# Churned Customers part 2 those customers who churned during the data outage\nusageFIXChurned2 = usageFIX[(usageFIX['CONTRACT_START']<= '2022-12-31') & (usageFIX['CHURNED_FLAG']== True) &  (usageFIX['CHURN_DATE'] <= '2023-06-24' ) & (usageFIX['YYYYWK'] <= 202252) & (usageFIX['CHURN_DATE'] >= '2023-01-01' )  ]\n\nidx = usageFIXChurned2.groupby('CUST_ACCOUNT_NUMBER')['YYYYWK'].idxmax()\nmax_scores = usageFIXChurned2.loc[idx]\nmax_scores['ywk'] = [(i -pd.to_datetime('2023-01-01')).days//7 for i in max_scores['CHURN_DATE']]\n\n# Method to duplicate rows\ndf_duplicated = max_scores.loc[np.repeat(max_scores.index.values, max_scores['ywk'])]\n\n# Reset index if needed\ndf_duplicated = df_duplicated.reset_index(drop=True)\n\n# Replace hard coded range\nstart_index = 0\nend_index = 23\nnew_values = recurring_range[0:24]\n\ndf_duplicated.loc[start_index:end_index, 'YYYYWK'] = new_values\n\n#  Replace hard coded range\nstart_index = 24\nend_index = 46\nnew_values = recurring_range[0:23]\n\ndf_duplicated.loc[start_index:end_index, 'YYYYWK'] = new_values\n\n#  Replace hard coded range\nstart_index = 47\nend_index = 56\nnew_values = recurring_range[0:10]\n\ndf_duplicated.loc[start_index:end_index, 'YYYYWK'] = new_values\n\n# Replace hard coded range\nstart_index = 57\nend_index = 80\nnew_values = recurring_range[0:24]\n\ndf_duplicated.loc[start_index:end_index, 'YYYYWK'] = new_values\n\n# Replace hard coded range\nstart_index = 81\nend_index = 87\nnew_values = recurring_range[0:7]\n\ndf_duplicated.loc[start_index:end_index, 'YYYYWK'] = new_values\n\n\n# save imputations for part 2 of churned customers\nchurned2 = df_duplicated\n\n\n#Combine imputations\nimputations = pd.concat([ActiveAccts,churned1,churned2])\n# drop added columns from imputations\nimputations = imputations.drop(columns=['Unnamed: 0','ywk'])\n\nusage = pd.concat([usageFIX,imputations])\n\n\n\n\nusage_latest = usage",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "76ffd01c-da72-484d-8cde-49b3cad55eaf",
   "metadata": {
    "language": "python",
    "name": "Sproc_5",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Fetching all the different views\npay_df = session.sql(\"SELECT * FROM RUS_AIML.PS_DOCUWARE_PAYMENTS_V\").to_pandas()\nrev_df = session.sql(\"SELECT * FROM RUS_AIML.PS_DOCUWARE_REVENUE_V\").to_pandas()\ntrx_df = session.sql(\"SELECT * FROM RUS_AIML.PS_DOCUWARE_TRX_V\").to_pandas()\ncontracts_sub_df = session.sql(\"SELECT * FROM RUS_AIML.PS_DOCUWARE_CONTRACTS_SUBLINE_V\").to_pandas()\nrenewals_df = session.sql(\"SELECT * FROM RUS_AIML.PS_DOCUWARE_RENEWALS_V\").to_pandas()\nl1_cust_df =  session.sql(\"SELECT * FROM RUS_AIML.PS_DOCUWARE_L1_CUST_V\").to_pandas()\ndnb_risk_df = session.sql(\"SELECT * FROM RUS_AIML.DNB_RISK_BREAKDOWN_V\").to_pandas()\n#usage_latest = session.sql(\"SELECT * FROM RUS_AIML.DOCUWARE_USAGE_JAPAN_V1_LATEST_V\").to_pandas()\n\n# Removing duplicates from all the pandas dataframes\npay_df = pay_df.drop_duplicates()\nrev_df = rev_df.drop_duplicates()\ntrx_df = trx_df.drop_duplicates()\ncontracts_sub_df = contracts_sub_df.drop_duplicates()\nrenewals_df = renewals_df.drop_duplicates()\nl1_cust_df = l1_cust_df.drop_duplicates()\ndnb_risk_df = dnb_risk_df.drop_duplicates()\nusage_latest = usage_latest.drop_duplicates()\n\n# Selecting active customers\n\nl1_cust_active = l1_cust_df[l1_cust_df[\"CHURNED_FLAG\"]==False]\n\npay_df_active = pay_df.merge(l1_cust_active[[\"CUST_ACCOUNT_NUMBER\"]], left_on = \"CUSTOMER_NO\", right_on = \"CUST_ACCOUNT_NUMBER\", how=\"inner\")\npay_df_active = pay_df_active.drop(\"CUSTOMER_NO\", axis=1)\npay_df_active[\"MONTH\"] = pd.to_datetime(pay_df_active[\"RECEIPT_DATE\"]).dt.to_period(\"M\").dt.to_timestamp()\n\nrev_df_active = rev_df.merge(l1_cust_active[[\"CUST_ACCOUNT_NUMBER\"]], on = \"CUST_ACCOUNT_NUMBER\", how=\"inner\")\nrev_df_active[\"MONTH\"] = pd.to_datetime(rev_df_active[\"DATE_INVOICE_GL_DATE\"]).dt.to_period(\"M\").dt.to_timestamp()\n\ntrx_df_active = trx_df.merge(l1_cust_active[[\"CUST_ACCOUNT_NUMBER\"]], left_on = \"ACCOUNT_NUMBER\", right_on = \"CUST_ACCOUNT_NUMBER\", how=\"inner\")\ntrx_df_active = trx_df_active.drop(\"ACCOUNT_NUMBER\", axis=1)\ntrx_df_active[\"MONTH\"] = pd.to_datetime(trx_df_active[\"TRX_DATE\"]).dt.to_period(\"M\").dt.to_timestamp()\n\np_r_t_merged = pay_df_active.merge(rev_df_active, on = [\"CUST_ACCOUNT_NUMBER\",\"MONTH\"], how=\"outer\").merge(trx_df_active, on = [\"CUST_ACCOUNT_NUMBER\",\"MONTH\"], how=\"outer\")\n\n#Contracts Subline\ncontracts_sub_df[\"SLINE_START_DATE\"] = pd.to_datetime(contracts_sub_df[\"SLINE_START_DATE\"])\ncontracts_sub_df[\"SLINE_END_DATE\"] = pd.to_datetime(contracts_sub_df[\"SLINE_END_DATE\"])\ncontracts_sub_df[\"SUB_START_MONTH\"] = pd.to_datetime(contracts_sub_df[\"SLINE_START_DATE\"]).dt.to_period(\"M\").dt.to_timestamp()\ncontracts_sub_df[\"SUB_END_MONTH\"] = pd.to_datetime(contracts_sub_df[\"SLINE_END_DATE\"]).dt.to_period(\"M\").dt.to_timestamp()\ncontracts_sub_df[\"SUB_EARLIEST_MONTH\"] = contracts_sub_df.groupby(\"CUST_ACCOUNT_NUMBER\")[\"SUB_START_MONTH\"].transform(\"min\")\ncontracts_sub_df[\"SUB_LATEST_MONTH\"] = contracts_sub_df.groupby(\"CUST_ACCOUNT_NUMBER\")[\"SUB_END_MONTH\"].transform(\"max\")\ncontracts_sub_df_active = contracts_sub_df.merge(l1_cust_active[[\"CUST_ACCOUNT_NUMBER\"]], on = \"CUST_ACCOUNT_NUMBER\", how=\"inner\")\n\ncontracts_sub_df_active = contracts_sub_df_active.drop_duplicates()\n\n# Renewals\ncols_to_str = [\"BILLTOCUSTOMERNUMBER\",\"SHIPTOCUSTNUM\"]\nrenewals_df[cols_to_str] = renewals_df[cols_to_str].astype(\"Int64\").astype(str)\n\nrenewals_df_active_1 = renewals_df.merge(l1_cust_active[[\"CUST_ACCOUNT_NUMBER\"]], left_on = \"SHIPTOCUSTNUM\", right_on = \"CUST_ACCOUNT_NUMBER\",  how=\"left\")\n\nrenewals_df_active_2 = renewals_df_active_1.merge(l1_cust_active[[\"CUST_ACCOUNT_NUMBER\"]], left_on = \"BILLTOCUSTOMERNUMBER\", right_on = \"CUST_ACCOUNT_NUMBER\",  how=\"left\", suffixes = (\"_1\", \"_2\"))\nrenewals_df_active_2[\"CUST_ACCOUNT_NUMBER\"] = renewals_df_active_2[\"CUST_ACCOUNT_NUMBER_1\"].fillna(renewals_df_active_2[\"CUST_ACCOUNT_NUMBER_2\"])\nrenewals_df_active_2 = renewals_df_active_2.drop([\"BILLTOCUSTOMERNUMBER\", \"SHIPTOCUSTNUM\",\"CUST_ACCOUNT_NUMBER_1\",\"CUST_ACCOUNT_NUMBER_2\"], axis=1)\nrenewals_df_active_2 = renewals_df_active_2.dropna()\n\nrenewals_df_active_2[\"STARTDATECOVERAGE\"] =  pd.to_datetime(renewals_df_active_2[\"STARTDATECOVERAGE\"])\nrenewals_df_active_2[\"RENEWALS_START_MONTH\"] = pd.to_datetime(renewals_df_active_2[\"STARTDATECOVERAGE\"]).dt.to_period(\"M\").dt.to_timestamp()\nrenewals_df_active_2[\"RENEWALS_END_MONTH\"] = pd.to_datetime(renewals_df_active_2[\"CONTRACT_END_DATE\"]).dt.to_period(\"M\").dt.to_timestamp()\nrenewals_df_active_2[\"RENEWALS_EARLIEST_MONTH\"] = renewals_df_active_2.groupby(renewals_df_active_2[\"CUST_ACCOUNT_NUMBER\"])[\"RENEWALS_START_MONTH\"].transform(\"min\")\nrenewals_df_active_2[\"RENEWALS_LATEST_MONTH\"] = renewals_df_active_2.groupby(renewals_df_active_2[\"CUST_ACCOUNT_NUMBER\"])[\"RENEWALS_END_MONTH\"].transform(\"max\")\n\n#DNB Risk Breakdown\ndnb_risk_df[\"ACCOUNT_NUMBER\"] = dnb_risk_df[\"ACCOUNT_NUMBER\"].astype(\"Int64\").astype(str)\ndnb_risk_df_active = dnb_risk_df.merge(l1_cust_active[[\"CUST_ACCOUNT_NUMBER\"]], left_on = \"ACCOUNT_NUMBER\", right_on = \"CUST_ACCOUNT_NUMBER\",  how=\"inner\")\ndnb_risk_df_active = dnb_risk_df_active.drop(\"ACCOUNT_NUMBER\", axis=1)\n\nusage_latest[\"YYYYWK_Transformed\"] = pd.to_datetime(usage_latest[\"YYYYWK\"].apply(convert_yyyywk_to_date), errors = \"coerce\")\n\n#Usage Japan Latest\nusage_latest[\"CUST_ACCOUNT_NUMBER\"] = usage_latest[\"CUST_ACCOUNT_NUMBER\"].astype(\"Int64\").astype(str)\n\nusage_latest[\"YYYYWK_MONTH\"] = pd.to_datetime(usage_latest[\"YYYYWK_Transformed\"]).dt.to_period(\"M\").dt.to_timestamp()\n\nusage_latest_active = usage_latest.merge(l1_cust_active[[\"CUST_ACCOUNT_NUMBER\"]], on=\"CUST_ACCOUNT_NUMBER\",  how=\"inner\")\n\n# Merging all the active customers data frames i.e. Payments, Revenue, Transactions, contracts, contracts subline, contracts topline, renewals, snow inc, tech survey, loyalty survey, dnb risk and usage latest\n\nmerged_1 = p_r_t_merged.merge(contracts_sub_df_active, left_on = [\"CUST_ACCOUNT_NUMBER\", \"MONTH\"], right_on = [\"CUST_ACCOUNT_NUMBER\", \"SUB_START_MONTH\"], how=\"outer\")\n\nmerged_1[\"MONTH\"] = merged_1[\"MONTH\"].fillna(merged_1[\"SUB_START_MONTH\"])\nmerged_1 = merged_1.drop(\"SUB_START_MONTH\", axis=1)\nmerged_2 = merged_1.merge(renewals_df_active_2, left_on = [\"CUST_ACCOUNT_NUMBER\",\"MONTH\"], right_on = [\"CUST_ACCOUNT_NUMBER\",\"RENEWALS_START_MONTH\"], how=\"outer\")\nmerged_2[\"MONTH\"] = merged_2[\"MONTH\"].fillna(merged_2[\"RENEWALS_START_MONTH\"])\nmerged_2 = merged_2.drop(\"RENEWALS_START_MONTH\", axis=1)\n\nmerged_3 = merged_2.merge(dnb_risk_df_active, on=\"CUST_ACCOUNT_NUMBER\", how=\"left\")\n\nmerged_4 = merged_3.merge(usage_latest_active, left_on= [\"CUST_ACCOUNT_NUMBER\",\"MONTH\"], right_on = [\"CUST_ACCOUNT_NUMBER\", \"YYYYWK_MONTH\"], how=\"outer\")\nmerged_4[\"MONTH\"] = merged_4[\"MONTH\"].fillna(merged_4[\"YYYYWK_MONTH\"])\n\nto_drop_2 = [\"CONTRACT_NUMBER\", \"CUST_PARTY_NAME\", \"CUSTOMER_NAME\", \"CONTRACT_END\",\"JAROWINKLER_SIMILARITY\"]\n#(A.CUST_PARTY_NAME, B.CUSTOMER_NAME)\n\nmerged_5 = merged_4.drop(to_drop_2, axis=1)\n\n#merged_5 = merged_4.merge(l1_cust_active[[\"CUST_ACCOUNT_NUMBER\", \"CHURNED_FLAG\"]], on = \"CUST_ACCOUNT_NUMBER\", how=\"inner\")\nmerged_5[\"EARLIEST_DATE\"] = merged_5[[\"RECEIPT_DATE\", \"DATE_INVOICE_GL_DATE\", \"TRX_DATE\", \"SLINE_START_DATE\", \"STARTDATECOVERAGE\"]].min(axis=1)\nmerged_5[\"FINAL_EARLIEST_DATE\"] = merged_5.groupby(\"CUST_ACCOUNT_NUMBER\")[\"EARLIEST_DATE\"].transform(\"min\")\n\nto_drop_3 = [\"RECEIPT_DATE\", \"DATE_INVOICE_GL_DATE\", \"TRX_DATE\", \"SLINE_START_DATE\", \"SLINE_END_DATE\", \"SUB_END_MONTH\",\"SLINE_STATUS\", \"SUB_EARLIEST_MONTH\", \"SUB_LATEST_MONTH\", \"STARTDATECOVERAGE\", \"CONTRACT_END_DATE\", \"RENEWALS_END_MONTH\", \"RENEWALS_EARLIEST_MONTH\",\"RENEWALS_LATEST_MONTH\", \"YYYYWK_MONTH\", \"PERIOD\", \"CHURNED_FLAG\", \"EARLIEST_DATE\"]\n\nmerged_5 = merged_5.drop(to_drop_3, axis=1)\n\ndate_col = [\"MONTH\",\"YYYYWK_Transformed\", \"FINAL_EARLIEST_DATE\"]\n\nmerged_5[date_col] = merged_5[date_col].astype(str)\n\nmerged_5 = merged_5.drop_duplicates()\n\nsession.write_pandas(merged_5, \"PS_DOCUWARE_RAW_DATA_PREDICTION\", auto_create_table=True, overwrite = True)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a4ac6f27-4c13-45ca-b6bc-38c9a8442d47",
   "metadata": {
    "name": "cell60",
    "collapsed": false
   },
   "source": "# Data Preprocessing of Live customers"
  },
  {
   "cell_type": "code",
   "id": "49680e97-477c-480b-aa64-18fa106a1400",
   "metadata": {
    "language": "python",
    "name": "Sproc_6",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Fetching from previous SPROC output table\nraw_df_active = session.sql(\"SELECT * FROM RUS_AIML.PS_DOCUWARE_RAW_DATA_PREDICTION\").to_pandas()\n\nnon_ts_numeric_cols = [\"PROBABILITY_OF_DELINQUENCY\", \"RICOH_CUSTOM_RISK_MODEL\"]\nnon_ts_categorical_cols = [\"OVERALL_BUSINESS_RISK\", \"PAYMENT_RISK_TRIPLE_A_RATING\", \"CONTRACT_LINE_ITEMS\"]\ncolumns_to_be_processed_later = non_ts_numeric_cols + non_ts_categorical_cols + [\"CUST_ACCOUNT_NUMBER\"]\nfinalized_df_ohe_to_process = raw_df_active.groupby(\"CUST_ACCOUNT_NUMBER\")[columns_to_be_processed_later].first()\n\n\n# Imputation for Non Time Series columns\npofd_median = finalized_df_ohe_to_process[\"PROBABILITY_OF_DELINQUENCY\"].median()\nfinalized_df_ohe_to_process[\"PROBABILITY_OF_DELINQUENCY\"] = finalized_df_ohe_to_process[\"PROBABILITY_OF_DELINQUENCY\"].apply(lambda x:   float(pofd_median) if np.isnan(x) else x)\n\nrcrm_mode = finalized_df_ohe_to_process[\"RICOH_CUSTOM_RISK_MODEL\"].mode()\nfinalized_df_ohe_to_process[\"RICOH_CUSTOM_RISK_MODEL\"] = finalized_df_ohe_to_process[\"RICOH_CUSTOM_RISK_MODEL\"].apply(lambda x: float(rcrm_mode) if np.isnan(x) else x)\n\n# One Hot Encoding for Categorical variables OVERALL_BUSINESS_RISK and PAYMENT_RISK_TRIPLE_A_RATING\nfinalized_df_ohe_to_process = finalized_df_ohe_to_process.reset_index(drop=True)\n\ncategorical_cols = [\"OVERALL_BUSINESS_RISK\", \"PAYMENT_RISK_TRIPLE_A_RATING\"]\nfill_value = \"UNK\"\n\nfor col in categorical_cols:\n    finalized_df_ohe_to_process[col].fillna(fill_value, inplace=True)\n    finalized_df_ohe_to_process[col] = finalized_df_ohe_to_process[col].str.replace(\" \", \"_\", regex=False)\n    \n    if col == \"OVERALL_BUSINESS_RISK\":\n        col_abreviation = \"obr_\"\n    else:\n        col_abreviation = \"prtar_\"\n        \n    le_ohe = LabelEncoder()\n    ohe = OneHotEncoder(handle_unknown = \"ignore\")\n    enc_train = le_ohe.fit_transform(finalized_df_ohe_to_process[col]).reshape(finalized_df_ohe_to_process.shape[0],1)\n    ohe_train = ohe.fit_transform(enc_train)\n    le_ohe_name_mapping = dict(zip(le_ohe.classes_, le_ohe.transform(le_ohe.classes_)))\n    \n    enc_train = finalized_df_ohe_to_process[col].map(le_ohe_name_mapping).ravel().reshape(-1,1)\n    enc_train[np.isnan(enc_train)] = 9999\n\n    cols = [col_abreviation + str(x) for x in le_ohe_name_mapping.keys()]\n    finalized_df_ohe_to_process = pd.concat([finalized_df_ohe_to_process.reset_index(), pd.DataFrame.sparse.from_spmatrix(ohe_train, columns = cols)], axis = 1).drop([\"index\"], axis=1)\n    finalized_df_ohe_to_process.drop([col], axis = 1, inplace=True)\n\ncolumns_to_be_droped = non_ts_categorical_cols+non_ts_numeric_cols\nraw_df_active.drop(columns_to_be_droped, axis=1, inplace=True)\n\n# Target Encoding for CONTRACT_LINE_ITEMS\nfinalized_df_ohe_to_process[\"CONTRACT_LINE_ITEMS\"].fillna(\"NA\", inplace=True)\nfinalized_df_ohe_to_process[\"CONTRACT_LINE_ITEMS\"] = finalized_df_ohe_to_process[\"CONTRACT_LINE_ITEMS\"].str.replace(r\"\\\\d+x \", \"\", regex=True)\n\nfor i, row in finalized_df_ohe_to_process.iterrows():\n    t = row[\"CONTRACT_LINE_ITEMS\"]\n    arr = t.split(\"-\")\n    arr = [x.strip() for x in arr]\n    arr_s = sorted(arr)\n    key = \"-\".join([s for s in arr_s])\n    finalized_df_ohe_to_process.loc[i, \"CONTRACT_LINE_ITEMS\"] = key\n\nstage_path = \"@PS_DOCUWARE_CHURN/ps_docuware_target_encoder_object\"\n\nX_train = finalized_df_ohe_to_process.copy()\n\nimport_dir = sys._xoptions.get(\"snowflake_import_directory\")\nenc_file = os.path.join('/tmp', 'ENC_CURRENT.joblib.gz')\nsession.file.get(\"@PS_DOCUWARE_CHURN/ps_docuware_target_encoder_object/ENC_CURRENT.joblib.gz\", '/tmp')\nenc = load(enc_file)\n\nX_train = X_train.reindex(columns = enc.feature_names_in_, fill_value=0)\nX_train_encoded = enc.transform(X_train)\n\n# Imputation for Time Series columns\nts_columns = [\"CUST_ACCOUNT_NUMBER\", \"YYYYWK\", \"DOCUMENTS_OPENED\", \"USED_STORAGE__MB\", \"INVOICE_REVLINE_TOTAL\", \"ORIGINAL_AMOUNT_DUE\", \"FUNCTIONAL_AMOUNT\"]\nraw_df_active[\"transformed_YYYYWK\"] = raw_df_active[\"MONTH\"].apply(convert_date_to_yyyywk)\n#Impute missing YYYYWK with equivalent MONTH\nraw_df_active[\"YYYYWK\"].fillna(raw_df_active[\"transformed_YYYYWK\"], inplace=True)\nraw_df_active.drop(\"transformed_YYYYWK\", axis=1, inplace=True)\nts_df = raw_df_active[ts_columns]\nts_df = ts_df[ts_df['YYYYWK'].notna()]\nts_df['YYYYWK'] = ts_df['YYYYWK'].astype(int)\nts_df['CUST_ACCOUNT_NUMBER'] = ts_df['CUST_ACCOUNT_NUMBER'].astype(int)\nts_df.rename(columns={'USED_STORAGE__MB':'USED_STORAGE_MB'},inplace=True)\nts_df_sorted = ts_df.sort_values(['CUST_ACCOUNT_NUMBER','YYYYWK']).drop_duplicates()\n\nonly_features = ts_df_sorted.copy()\nonly_features = only_features.fillna(0)\n\n#ts_comprehensive_df = session.sql(\"SELECT * FROM RAC_RAPID_DEV.RUS_AIML.PS_DOCUWARE_PREDICTION_TS_DF_ONLY\").to_pandas()\n#training_set_ts_df = session.sql(\"SELECT * FROM RAC_RAPID_DEV.RUS_AIML.PS_DOCUWARE_ONLY_TS_DF\").to_pandas()\n\n\n#ts_comprehensive_df_active = time_series_ts_fresh_features(only_features)\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4bb621d1-afd2-44cc-9de1-ec7e0786bec3",
   "metadata": {
    "name": "cell61",
    "collapsed": false
   },
   "source": "# Store Live Customers' TimeSeries data before TSFRESH into DB"
  },
  {
   "cell_type": "code",
   "id": "b0b4fbd6-fb91-484a-8fa4-49fd0def0e7d",
   "metadata": {
    "language": "python",
    "name": "cell194"
   },
   "outputs": [],
   "source": "session.write_pandas(only_features, \"PS_DOCUWARE_LIVE_RAW_DATA_BEFORE_TSFRESH\", auto_create_table=True, overwrite = True)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "822786d0-2e57-47e9-b4ab-304c59f9bb07",
   "metadata": {
    "language": "sql",
    "name": "cell183"
   },
   "outputs": [],
   "source": "/*WITH fi(CUST_ACCOUNT_NUMBER, YYYYWK) AS(\n    SELECT CUST_ACCOUNT_NUMBER, min(YYYYWK) AS YY FROM RUS_AIML.DOCUWARE_USAGE_JAPAN_V1_LATEST_V GROUP BY(CUST_ACCOUNT_NUMBER)\n)\n\nSELECT a.CUST_ACCOUNT_NUMBER, a.YYYYWK FROM fi a join RUS_AIML.PS_DOCUWARE_L1_CUST b on a.CUST_ACCOUNT_NUMBER = b.CUST_ACCOUNT_NUMBER where b.CHURNED_FLAG=False;*/",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9d40fa9a-582d-40a9-aaad-bd678361ee8b",
   "metadata": {
    "language": "python",
    "name": "cell184"
   },
   "outputs": [],
   "source": "#all_usage = cell183.to_pandas()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d964a8c1-4545-4137-ab47-2723a958d115",
   "metadata": {
    "language": "python",
    "name": "cell199"
   },
   "outputs": [],
   "source": "#all_usage",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "56e9cb1d-4d15-4ee8-b8e6-7cb1ae153756",
   "metadata": {
    "language": "python",
    "name": "cell188",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#all_usage.loc[:'YYYYWK'] = 202336",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "99c23b40-8de3-4c24-8482-c95f73838717",
   "metadata": {
    "language": "python",
    "name": "cell189"
   },
   "outputs": [],
   "source": "#all_usage.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bf3d4467-fab1-400d-a523-a0aefd07eba4",
   "metadata": {
    "language": "python",
    "name": "cell185"
   },
   "outputs": [],
   "source": "\"\"\"raw_df = session.sql(\"SELECT * FROM RAC_RAPID_DEV.RUS_AIML.PS_DOCUWARE_RAW_DATA_PREDICTION\").to_pandas()\n# CK 5-21 not sure why extraction was used over prediction raw_df = session.sql(\"SELECT * FROM RAC_RAPID_DEV.RUS_AIML.PS_DOCUWARE_RAW_DATA_EXTRACTION\").to_pandas()\ndf_cust_earliest_date = raw_df[['CUST_ACCOUNT_NUMBER', 'FINAL_EARLIEST_DATE']]\ndf_cust_earliest_date.drop_duplicates(inplace=True)\ndf_cust_earliest_date['CUST_ACCOUNT_NUMBER'] = df_cust_earliest_date['CUST_ACCOUNT_NUMBER'].astype(int)\nall_usage['CUST_ACCOUNT_NUMBER'] = all_usage['CUST_ACCOUNT_NUMBER'].astype(int)\ndf_merged = pd.merge(df_cust_earliest_date, all_usage , on='CUST_ACCOUNT_NUMBER', how='inner')\"\"\"",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d686f76a-096b-4382-b006-0708ed4d43d0",
   "metadata": {
    "language": "python",
    "name": "cell195",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#raw_df.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "939ce172-4e51-46ab-a9c7-588bf5684fac",
   "metadata": {
    "language": "python",
    "name": "cell190",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "df_merged.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "594acd4c-500e-4cb5-b23f-4acda26fb4bc",
   "metadata": {
    "language": "python",
    "name": "cell193",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#final_features_for_FE",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9dccf40d-968e-405c-84ff-f6cdbb6a2ca7",
   "metadata": {
    "language": "python",
    "name": "cell186",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "\"\"\"df_merged['CUST_ACCOUNT_NUMBER'] = df_merged['CUST_ACCOUNT_NUMBER'].astype(int)\nfinal_features_for_FE['CUST_ACCOUNT_NUMBER'] = final_features_for_FE['CUST_ACCOUNT_NUMBER'].astype(int)\nfinal_features_for_FE_trimmed = pd.DataFrame()\n\nfor ind,row in df_merged.iterrows():   \n    t = final_features_for_FE[ final_features_for_FE['CUST_ACCOUNT_NUMBER'] == row['CUST_ACCOUNT_NUMBER'] ]\n    t['YYYYWK'] = t['YYYYWK'].astype(int)\n    yyyywk_date = convert_yyyywk_to_actual_mid_date(row['YYYYWK'])\n    \n    row['YYYYWK'] = int(row['YYYYWK'])\n    tt = t[ t['YYYYWK'] >= row['YYYYWK'] ]\n    tt['DAYS_TO_CHURN'] = tt['DAYS_TO_CHURN'] - (pd.to_datetime(yyyywk_date) - pd.to_datetime(row['FINAL_EARLIEST_DATE'])).days\n    final_features_for_FE_trimmed = pd.concat([tt, final_features_for_FE_trimmed], axis=0, ignore_index=True)\"\"\"",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "055e3b32-81fb-4e34-b629-2d4513a12e5c",
   "metadata": {
    "language": "python",
    "name": "cell187",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#final_features_for_FE_trimmed.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8481c003-c881-4eec-9b30-9515250eb028",
   "metadata": {
    "language": "python",
    "name": "cell45"
   },
   "outputs": [],
   "source": "#session.write_pandas(final_features_for_FE_trimmed, \"PS_DOCUWARE_LIVE_RAW_DATA_BEFORE_TSFRESH\", auto_create_table=True, overwrite = True)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "09c8fd21-577e-4549-8c5e-c5fdaca5687d",
   "metadata": {
    "name": "cell62",
    "collapsed": false
   },
   "source": "# Feature Engineering using TSFRESH"
  },
  {
   "cell_type": "code",
   "id": "7db422db-f6ff-4d67-8967-6770b7dc66ba",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": "#CK 5-21 ts_comprehensive_df_active = engineer_timeseries_cols_using_tsfresh_for_live_customers(final_features_for_FE_trimmed)\nts_comprehensive_df_active = engineer_timeseries_cols_using_tsfresh_for_live_customers(only_features)\nts_comprehensive_df_active = ts_comprehensive_df_active.replace([np.inf, -np.inf], 0)\nts_comprehensive_df_active = ts_comprehensive_df_active.fillna(0)\ntraining_set_ts_df = ts_comprehensive_df_active.copy()\nsame_features = training_set_ts_df.columns",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "670f2357-8f51-4c82-a862-470fec01fe6f",
   "metadata": {
    "language": "python",
    "name": "cell6"
   },
   "outputs": [],
   "source": "#same_features\n#ts_comprehensive_df_active = fts_comprehensive_df_active",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "35cebbbe-fe7d-4c2d-b64c-234744a9d420",
   "metadata": {
    "name": "cell63"
   },
   "source": "# Store LIVE Customers' TSFRESH time series generated features"
  },
  {
   "cell_type": "code",
   "id": "89a7db38-0860-4e80-a0e1-999bdeeda4c9",
   "metadata": {
    "language": "python",
    "name": "cell15"
   },
   "outputs": [],
   "source": "ts_comprehensive_df_active.shape\nsession.write_pandas(ts_comprehensive_df_active, \"PS_DOCUWARE_LIVE_CUSTOMER_FEATURES\", auto_create_table=True, overwrite = True)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7810892b-f161-4fbe-b25f-e1cafdd395d5",
   "metadata": {
    "language": "python",
    "name": "cell40"
   },
   "outputs": [],
   "source": "# #comprehensive_imputed_df_active['FINAL_EARLIEST_DATE']\n# temp = raw_df_active[['CUST_ACCOUNT_NUMBER', 'FINAL_EARLIEST_DATE']].drop_duplicates()\n# temp.shape, ts_comprehensive_df_active.shape, X_train_encoded.shape",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "64c93071-8cd9-4bda-addd-50c5faf6f77f",
   "metadata": {
    "name": "cell64"
   },
   "source": "# Data preprocessing to prepare it for inferencing "
  },
  {
   "cell_type": "code",
   "id": "67f6a561-2168-4d86-bcf6-d544240c0c8e",
   "metadata": {
    "language": "python",
    "name": "cell8",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "ts_comprehensive_df_active = ts_comprehensive_df_active.reindex(columns=same_features, fill_value=0)\nts_comprehensive_df_active[\"CUST_ACCOUNT_NUMBER\"] = ts_comprehensive_df_active[\"CUST_ACCOUNT_NUMBER\"].astype(int)\n\nX_train_encoded[\"CUST_ACCOUNT_NUMBER\"] = X_train_encoded[\"CUST_ACCOUNT_NUMBER\"].astype(int)\ndf_earliest_date = raw_df_active[['CUST_ACCOUNT_NUMBER', 'FINAL_EARLIEST_DATE']].drop_duplicates()\ndf_earliest_date[\"CUST_ACCOUNT_NUMBER\"] = df_earliest_date[\"CUST_ACCOUNT_NUMBER\"].astype(int)\n\ncomprehensive_imputed_df_active = pd.merge(ts_comprehensive_df_active, X_train_encoded, on=\"CUST_ACCOUNT_NUMBER\", how=\"inner\")\ncomprehensive_imputed_df_active = pd.merge(comprehensive_imputed_df_active, df_earliest_date, on=\"CUST_ACCOUNT_NUMBER\", how=\"inner\")\ncomprehensive_imputed_df_active['CREATION_DATE'] = pd.Timestamp.today().date()\n\n#comprehensive_imputed_df_active['DAYS_ELAPSED_TILL_DATE'] = (pd.to_datetime(comprehensive_imputed_df_active['CREATION_DATE']) - pd.to_datetime(comprehensive_imputed_df_active['FINAL_EARLIEST_DATE'])).dt.days\n\n#stratified_df_active = pd.DataFrame()\n\n# Get CLUSTER Information in the dataframe\n#label_count=1\n# for i in range(365, 1461, 365):\n#     XX = comprehensive_imputed_df_active[((i-365) < comprehensive_imputed_df_active[\"DAYS_ELAPSED_TILL_DATE\"]) & (comprehensive_imputed_df_active[\"DAYS_ELAPSED_TILL_DATE\"] <= i)]\n#     #XX[\"SAMPLE\"] = label_count\n#     stratified_df_active = pd.concat([stratified_df_active, XX], axis=0, ignore_index=True)\n#     #label_count+=1\n   \n#     if i==1460:\n#         XX = comprehensive_imputed_df_active[1460 < comprehensive_imputed_df_active[\"DAYS_ELAPSED_TILL_DATE\"]]\n#         #XX[\"SAMPLE\"] = label_count\n#         stratified_df_active = pd.concat([stratified_df_active, XX], axis=0, ignore_index=True)\n\ncomprehensive_imputed_df_active_with_cluster = comprehensive_imputed_df_active.copy()\n# comprehensive_imputed_df_active_with_cluster = stratified_df_active.copy()\n\nfor col in comprehensive_imputed_df_active_with_cluster.columns:\n    if pd.api.types.is_sparse(comprehensive_imputed_df_active_with_cluster[col]):\n        comprehensive_imputed_df_active_with_cluster[col] = comprehensive_imputed_df_active_with_cluster[col].sparse.to_dense()\n\n#import_dir = sys._xoptions.get(\"snowflake_import_directory\")        \nmodel_file = os.path.join('/tmp', 'xgb.joblib.gz')\nsession.file.get(\"@PS_DOCUWARE_CHURN/ps_docuware_churn_model/xgb.joblib.gz\", \"/tmp\")\nbest_model = load(model_file)\n\n#input_features = comprehensive_imputed_df_active_with_cluster.drop([\"CUST_ACCOUNT_NUMBER\", \"CREATION_DATE\", \"DAYS_ELAPSED_TILL_DATE\"], axis=1)\ninput_features = comprehensive_imputed_df_active_with_cluster.drop([\"CUST_ACCOUNT_NUMBER\", \"CREATION_DATE\"], axis=1)\n\ninput_features = convert_to_float(input_features)\ninput_features = input_features.reindex(columns=best_model.feature_names_in_, fill_value=0)\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cd0682cf-9f4a-479e-9f40-8a048bc8a788",
   "metadata": {
    "language": "python",
    "name": "cell209"
   },
   "outputs": [],
   "source": "#import_dir = sys._xoptions.get(\"snowflake_import_directory\")        \n#model_file = os.path.join('/tmp', 'xgb.joblib.gz')\n#session.file.get(\"@PS_DOCUWARE_CHURN/ps_docuware_churn_model/xgb.joblib.gz\", \"/tmp\")\n#best_model = load(model_file)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fb9af38b-094d-44c5-8f6b-cb7377ca51f3",
   "metadata": {
    "language": "python",
    "name": "cell210"
   },
   "outputs": [],
   "source": "#best_model",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cf7eda96-95f7-49f9-9f0b-b07b6a07d633",
   "metadata": {
    "language": "python",
    "name": "cell211"
   },
   "outputs": [],
   "source": "best_model.get_params()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ed3930ac-365f-45fc-add6-e90afd379ddf",
   "metadata": {
    "language": "python",
    "name": "cell200",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "input_features",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0a13b7e7-bb4b-4097-af08-1976b7c9b8dd",
   "metadata": {
    "name": "cell68",
    "collapsed": false
   },
   "source": "# Store features of Live Customers into Staging"
  },
  {
   "cell_type": "code",
   "id": "9ccf4a66-faad-4fd9-ad63-2c7777224f74",
   "metadata": {
    "language": "python",
    "name": "cell21"
   },
   "outputs": [],
   "source": "df_live_customers = session.create_dataframe(input_features)\n#df_live_customers.write.copy_into_location(\"@PS_DOCUWARE_CHURN/df_live_customers_21Apr2025.csv\", file_format_type=\"csv\", format_type_options={\"COMPRESSION\": \"NONE\"}, header=True, overwrite=True )\n        ",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "20271eb5-2e02-4721-8a07-b7960817dda3",
   "metadata": {
    "name": "cell69"
   },
   "source": "# Store features of Live Customers into DB"
  },
  {
   "cell_type": "code",
   "id": "a85b9827-89e4-4f01-a066-4406fd030f1b",
   "metadata": {
    "language": "python",
    "name": "cell201"
   },
   "outputs": [],
   "source": "df_live_customers",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c3932800-2e79-43f7-95f5-649c30641b06",
   "metadata": {
    "language": "python",
    "name": "cell203"
   },
   "outputs": [],
   "source": "type(df_live_customers)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9bad6465-1767-4f4b-9494-8ded53efca0b",
   "metadata": {
    "language": "python",
    "name": "cell202",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "session.write_pandas(df_live_customers, \"PS_DOCUWARE_LIVE_CUSTOMER_FEATURES\", auto_create_table=True, overwrite = True)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "71a28eeb-76b0-4a1e-919a-734563bf7b4f",
   "metadata": {
    "language": "python",
    "name": "cell23",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "session.write_pandas(df_live_customers, \"PS_DOCUWARE_LIVE_CUSTOMER_FEATURES\", auto_create_table=True, overwrite = True)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9aa3a07c-4823-4c68-a1fc-ae38c355923f",
   "metadata": {
    "language": "python",
    "name": "cell22"
   },
   "outputs": [],
   "source": "import shap\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0f7add6e-6df4-4282-8300-c98d0919fd1d",
   "metadata": {
    "name": "cell65"
   },
   "source": "# Inferencing for Live customers to predict the churn duration"
  },
  {
   "cell_type": "code",
   "id": "3ff11f92-9fba-45e4-a1e3-937f736cf35c",
   "metadata": {
    "language": "python",
    "name": "cell19",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "y_pred_transformed = best_model.predict(input_features)\nremaining_months = y_pred_transformed/30\n#lifespan_months = np.exp(y_pred_transformed)\n\nfinal_predicted_df = pd.DataFrame({\n    \"CUST_ACCOUNT_NUMBER\": comprehensive_imputed_df_active[\"CUST_ACCOUNT_NUMBER\"].astype(str),\n    \"MONTHS_REMAINING\": remaining_months\n})\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "23c297fc-cf51-4cd8-8e78-0a88c073af30",
   "metadata": {
    "language": "python",
    "name": "cell94"
   },
   "outputs": [],
   "source": "final_predicted_df.head(50)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c7d86fce-883a-4a53-8568-4c5762ab657e",
   "metadata": {
    "language": "python",
    "name": "cell17"
   },
   "outputs": [],
   "source": "raw_df_active_1 = raw_df_active[['CUST_ACCOUNT_NUMBER', 'FINAL_EARLIEST_DATE']].drop_duplicates()\n\nfinal_predicted_df = final_predicted_df.merge(raw_df_active_1, on='CUST_ACCOUNT_NUMBER', how='inner')\n\nfinal_predicted_df['CREATION_DATE'] = pd.Timestamp.today().date()\nfinal_predicted_df = final_predicted_df.rename({'FINAL_EARLIEST_DATE':'EARLIEST_START_DATE'})\n\n\nfinal_predicted_df['DAYS_ELAPSED'] = (pd.to_datetime(final_predicted_df['CREATION_DATE']) - pd.to_datetime(final_predicted_df['FINAL_EARLIEST_DATE'])).dt.days\nfinal_predicted_df['MONTHS_ELAPSED'] = (pd.to_datetime(final_predicted_df['CREATION_DATE']) - pd.to_datetime(final_predicted_df['FINAL_EARLIEST_DATE'])).dt.days/30\n#final_predicted_df['MONTHS_REMAINING'] = final_predicted_df['LIFESPAN_MONTHS'] #- final_predicted_df['MONTHS_ELAPSED']\nfinal_predicted_df['LIFESPAN_MONTHS'] = final_predicted_df['MONTHS_REMAINING'] + final_predicted_df['MONTHS_ELAPSED']\nfinal_predicted_df.head(100)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "44bb8a22-1572-474f-b742-89b73366aedd",
   "metadata": {
    "name": "cell66"
   },
   "source": "# Store Prediction for Live customers into DB"
  },
  {
   "cell_type": "code",
   "id": "8ce4dfde-e31d-4638-94b7-f96e31e466a9",
   "metadata": {
    "language": "python",
    "name": "cell18"
   },
   "outputs": [],
   "source": "session.write_pandas(final_predicted_df, \"PS_DOCUWARE_PREDICTION_DATA_NEW\", auto_create_table=True, overwrite = True)\nsession.sql(\"INSERT INTO rus_aiml.PS_DOCUWARE_PREDICTION_DATA_ARCHIVE SELECT * FROM rus_aiml.PS_DOCUWARE_PREDICTION_DATA_NEW WHERE CREATION_DATE not in (select creation_date from rus_aiml.PS_DOCUWARE_PREDICTION_DATA_ARCHIVE)\")\n#session.sql(\"INSERT INTO PS_DOCUWARE_PREDICTION_DATA_ARCHIVE SELECT * FROM PS_DOCUWARE_PREDICTION_DATA_NEW WHERE CREATION_DATE != CURRENT_DATE()\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0b322c94-f953-4af9-9d8c-8487f1d91c33",
   "metadata": {
    "name": "cell169",
    "collapsed": false
   },
   "source": "# Shap analysis"
  },
  {
   "cell_type": "code",
   "id": "9cd536de-c570-49e6-b281-b1388c78952b",
   "metadata": {
    "language": "python",
    "name": "cell24"
   },
   "outputs": [],
   "source": "!pip install shap",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dfbe4251-cd04-46c7-bcd3-5f752ff3993a",
   "metadata": {
    "language": "python",
    "name": "cell170"
   },
   "outputs": [],
   "source": "# # Inferencing\n# y_pred = best_models.predict(test_25_X)\n# remaining_months = y_pred/30\n# print(remaining_months.shape)\n\n# actual_remaining = test_25_y/30\n# final_test_predicted_df = pd.DataFrame({\n#     \"CUST_ACCOUNT_NUMBER\": last_rows_X_test.loc[test_25_X.index,\"CUST_ACCOUNT_NUMBER\"].astype(str),\n#     \"PREDICTED_MONTHS_REMAINING\": remaining_months,\n#     \"ACTUAL_MONTH_REMAINING\": actual_remaining,\n#     \"RESIDUAL\": abs(remaining_months-actual_remaining)\n# })\n\n# final_test_predicted_df.head(50)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "681158ff-6753-4e2f-97c9-ab71c9a451b6",
   "metadata": {
    "language": "python",
    "name": "cell26"
   },
   "outputs": [],
   "source": "model_file = os.path.join('/tmp', 'xgb.joblib.gz')\nsession.file.get(\"@PS_DOCUWARE_CHURN/ps_docuware_churn_model/xgb.joblib.gz\", \"/tmp\")\nbest_model = load(model_file)\n#live_features = session.sql(\"SELECT * FROM RUS_AIML.PS_DOCUWARE_LIVE_CUSTOMER_FEATURES\").to_pandas()\nexplainer = shap.Explainer(best_model.predict, test_25_X)\nshap_values = explainer.shap_values(test_25_X)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "18835767-cd4a-46e1-8f7d-936856dbe90e",
   "metadata": {
    "language": "python",
    "name": "cell27"
   },
   "outputs": [],
   "source": "shap_values.shape",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "08e37f81-de4c-43e7-b127-1d4bf779c13e",
   "metadata": {
    "language": "python",
    "name": "cell28"
   },
   "outputs": [],
   "source": "shap.summary_plot(shap_values)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1f8bcce4-5d4d-4dc9-9f09-6af001926575",
   "metadata": {
    "language": "python",
    "name": "cell29"
   },
   "outputs": [],
   "source": "shap.summary_plot(shap_values, plot_type='violin')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "edb2ddcc-316b-43c1-8716-259a45cb9593",
   "metadata": {
    "language": "python",
    "name": "cell33"
   },
   "outputs": [],
   "source": "\nfeature_importance = global_shap_importance(best_models, test_25_X)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "248a416d-dad3-40dc-a648-5d5b13c7da32",
   "metadata": {
    "language": "python",
    "name": "cell34"
   },
   "outputs": [],
   "source": "feature_importance_top40 = feature_importance.head(40)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c58576f6-aaea-414b-811a-3be1a947820a",
   "metadata": {
    "name": "cell67"
   },
   "source": "# Plot of Shap to get top 40 important features for Live customer's churn prediction"
  },
  {
   "cell_type": "code",
   "id": "0103537c-99dc-4f4d-94d7-87ef04722b3c",
   "metadata": {
    "language": "python",
    "name": "cell35"
   },
   "outputs": [],
   "source": "# Sample data\ny = feature_importance_top40['importance']\nx = feature_importance_top40['features']\n\n# Create a figure and a set of subplots with a specified size\nfig, ax = plt.subplots(figsize=(40, 30))  # width=12 inches, height=8 inches\n\n# Plot the data on the axes\nax.plot(x, y)\n\n# Add labels and title\nax.set_xlabel('importance score')\nax.set_ylabel('Features')\nax.set_title('Graph of Top 40 Feature vs Importance While Predicting Input of 405 customers')\nplt.xticks(x, x, rotation=45, ha='right')\n#plt.savefig('C:/My Documents/work/Projects/Short Term Goal 2 - Customer Churn Prediction/ML Modeling Phase/Shap_Top_30_Importance_Features.png')\n# Show the plot\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "30dcef83-2b8b-479c-96f2-e363724f157a",
   "metadata": {
    "language": "python",
    "name": "cell172"
   },
   "outputs": [],
   "source": "test_25_index = test_25_X.index",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5ea6837e-5270-4fdf-9520-bb2276c3d2c1",
   "metadata": {
    "language": "python",
    "name": "cell173"
   },
   "outputs": [],
   "source": "test_25_X.shape",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f6c290f4-e0c3-47c1-aaa0-330186ec07ae",
   "metadata": {
    "language": "python",
    "name": "cell174"
   },
   "outputs": [],
   "source": "test_25_index",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fdde1baf-9573-42fd-8789-270e65e29a6f",
   "metadata": {
    "language": "python",
    "name": "cell175"
   },
   "outputs": [],
   "source": "for ind,row in test_25_X.iterrows():\n    print(ind)\n    temp = pd.DataFrame([row])\n    print(temp.shape)\n    shap_values = explainer.shap_values(temp)\n    shap.summary_plot(shap_values, plot_type='violin')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c3a8442a-bf0e-45c4-930d-425c80bd901b",
   "metadata": {
    "language": "python",
    "name": "cell171"
   },
   "outputs": [],
   "source": "for ind,row in test_25_X.iterrows():\n    print(ind)\n    temp = pd.DataFrame([row])\n    print(temp.shape)\n    feature_importance = global_shap_importance(best_models, temp)\n    \n    feature_importance_top40 = feature_importance.head(40)\n    \n    # Sample data\n    y = feature_importance_top40['importance']\n    x = feature_importance_top40['features']\n    \n    # Create a figure and a set of subplots with a specified size\n    fig, ax = plt.subplots(figsize=(40, 30))  # width=12 inches, height=8 inches\n    \n    # Plot the data on the axes\n    ax.plot(x, y)\n    \n    # Add labels and title\n    ax.set_xlabel('importance score')\n    ax.set_ylabel('Features')\n    ax.set_title('Graph of Top 40 Feature vs Importance While Predicting Input of 405 customers')\n    plt.xticks(x, x, rotation=45, ha='right')\n    #plt.savefig('C:/My Documents/work/Projects/Short Term Goal 2 - Customer Churn Prediction/ML Modeling Phase/Shap_Top_30_Importance_Features.png')\n    # Show the plot\n    plt.show()\n   ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fd985ed3-8ac6-4205-8ff9-d59ec8636a35",
   "metadata": {
    "language": "python",
    "name": "cell25"
   },
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\n\nx = [1, 2, 3, 4, 5]\ny = [2, 4, 1, 3, 5]\n\nplt.plot(x, y, marker='o', linestyle='-', color='b', label='Data Points')\nplt.xlabel('X-axis')\nplt.ylabel('Y-axis')\nplt.title('My Graph')\nplt.legend()\n\ngraph_file = os.path.join(\"/tmp\", \"graph_new.jpg\")\nplt.savefig(graph_file)\nsession.file.put(graph_file, \"@PS_DOCUWARE_CHURN/graph_new.jpg\",overwrite=True)\n\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "62572d86-c569-4a21-8e66-647200a6d1fd",
   "metadata": {
    "language": "sql",
    "name": "cell31"
   },
   "outputs": [],
   "source": " PUT /tmp/graph_new.jpg @PS_DOCUWARE_CHURN/ OVERWRITE=TRUE;",
   "execution_count": null
  }
 ]
}